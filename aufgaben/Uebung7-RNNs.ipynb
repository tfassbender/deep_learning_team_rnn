{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 7 - Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Übung wirst du ein RNN mittels Keras selbst erstellen und trainieren.\n",
    "\n",
    "Das RNN soll Zeichenketten der Form `123+654` Zeichen für Zeichen one-hot kodiert als Eingabe erhalten und anschließend das Ergebnis der beschriebenen Rechnung zeichenweise ausgeben.\n",
    "Es handelt sich hierbei also um *sequence to sequence learning*, da wir aus einer Eingabesequenz anschließend eine Ausgabesequenz erzeugen.\n",
    "\n",
    "Die Trainingsdaten, auf denen wir das Netz trainieren, können wir selbst erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, RepeatVector, TimeDistributed, Dense, Input, Lambda\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst benötigen wir eine Klasse, welche die one-hot Kodierung und Dekodierung übernimmt.\n",
    "\n",
    "**Aufgabe**: Implementiere eine Klasse, welche zu Kodierung und Dekodierung der Eingabesequenzen verwendet werden kann. Diese soll folgende Funktionalitäten bieten:\n",
    "* Übergabe das Alphabets als Zeichenkette bei der Objekterzeugung\n",
    "* Kodierung eines Strings: Umwandlung eines Strings in eine Matrix, welche die Vektoren aus der one-hot kodierten Eingabe enthält. Zusätzlich soll eine Länge `length` angegeben werden, bis zu welcher Länge die Zeichenkette mit Leerzeichen aufgefüllt wird.\n",
    "    * Dimensionen der entstehenden Matrix: `(length, alphabet_length)`\n",
    "    * **Hinweis**: Dieses Auffüllen der Sequenz mit Leerzeichen erleichtert uns später die Erstellung des Modells. Natürlich eignen sich RNNs auch dazu Sequenzen unterschiedlicher Länge als Eingabe einzulesen, was diesen Schritt in anderen Fällen obsolet macht.\n",
    "* Dekodierung eines Vektors. Als Eingabe erhält die Funktionen einen Vektor mit den Wahrscheinlichkeiten der Auswahl der Zeichen, also einen Vektor mit `alphabet_length` Einträgen. Hier reicht es aus das Zeichen, welches mit höchster Wahrscheinlichkeit ausgewählt wird, zu ermitteln und zurückzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erzeugung der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Training des Netzes benötigen wir Trainingsdaten, welche wir uns in ausreichender Menge selbst erstellen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Erstelle eine Funktion, welche Trainingsdaten einer bestimmten Größe für unsere Problemstellung erzeugt.\n",
    "* Per Parameter kann diese eine Anzahl Ziffern übergeben bekommen, aus denen eine Zahl maximal bestehen darf.\n",
    "* Beachte dabei: Diese Funktion gibt Zeichenketten, keine `integer` zurück\n",
    "* Es sollte keine Aufgabe mehrfach in den Daten vorkommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Erzeuge einen Datensatz mit 50000 Einträgen, welchen wir für das Training benutzen und erzeuge die One-Hot kodierte Matrix dieses Datensatzes.\n",
    "Teile diesen anschließend in 20% Validierungs- und 80% Trainingsdatensatz ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Lösung unseres Problems benötigen wir ein Sequence-to-Sequence Modell, also ein Modell, welches zunächst elementweise eine Eingabesequenz erhält und anschließend, ebenfalls elementweise, eine Ausgabesequenz ausgibt.\n",
    "Das Einlesen geschieht im Encoder (im Bild weiß), das anschließende Auswerten des sich ergebenden Zellzustandes im Decoder (grau), welche beide RNN-Zellen sind.\n",
    "Wir verwenden hier zunächst LSTM-Zellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sequence to Sequence Modell](seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir bauen dieses Modell wie folgt mit Hilfe von `Sequential` in Keras auf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256\n",
    "ALPHABET_LENGTH = len('0123456789+ ')\n",
    "MAXLEN = DIGITS * 2 + 1 # Maximallänge eines Eingabestrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(MAXLEN, ALPHABET_LENGTH))) # Encoder\n",
    "model.add(RepeatVector(DIGITS + 1))  # Stellt dem RNN im nächsten Schritt die Ausgabe des vorherigen bereit\n",
    "model.add(LSTM(HIDDEN_SIZE, return_sequences=True)) # Decoder\n",
    "model.add(TimeDistributed(Dense(ALPHABET_LENGTH, activation='softmax'))) # Wendet eine `Dense` Schicht auf jede Ausgabe des Decoders an\n",
    "                                # und ermittelt mittels 'softmax'-Funktion die Auswahlwahrscheinlichkeiten der Zeichen\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben**: Trainiere das oben erstellte Netz für 50 Epochen. Denke daran einen Teil der Daten zur Validation zu verwenden.\n",
    "* Implementiere die untenstehende Funktion `train`\n",
    "* Um den Trainingsfortschritt zu beobachten soll nach jeder fünften Epoche eine Ausgabe erzeugt werden, in der zehn Einträge des **Valisierungs**datensatzes und die vom neuronalen Netz erzeugten Ausgabesequenzen visualisiert werden. Hierbei sollte auch sichtbar sein, ob die Ausgabe des Netzes korrekt war. Wer möchte kann dazu die untenstehende Klasse `colors` verwenden, um mit ANSI color codes die Ausgabe einzufärben.\n",
    "* Führe `train` aus. Plotte den Verlauf von `loss` und `accuracy`, sowohl auf dem Trainings- als auch auf dem Validierungsset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_val, y_val, encoder, epochs):\n",
    "    loss, acc, val_loss, val_acc = [], [], [], []\n",
    "    \n",
    "    #TODO\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    return loss, acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtraktion statt Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Wir werden nun das oben stehende Netz auf Subtraktion statt Addition trainieren.\n",
    "Implementiere dazu eine Funktion oder ändere die obenstehende ab, um entsprechende Trainingsdaten zu erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Erzeuge wie oben einen Datensatz und One-Hot-Kodiere ihn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Trainiere sowohl ein \"frisches\", untrainiertes Netz so wie eine Kopie des zuvor auf die Addition trainierten Netzes wie oben beschrieben und vergleiche den Trainingserfolg. Was fällt auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Ändere die zuvor verwendete Netzarchitektur so ab, dass anstelle von `LSTM`s `SimpleRNN`s oder `GRU`s verwendet werden, trainiere diese und vergleiche erneut den Lernerfolg. Was fällt auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

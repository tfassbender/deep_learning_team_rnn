{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 7 - Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Übung wirst du ein RNN mittels Keras selbst erstellen und trainieren.\n",
    "\n",
    "Das RNN soll Zeichenketten der Form `123+654` Zeichen für Zeichen one-hot kodiert als Eingabe erhalten und anschließend das Ergebnis der beschriebenen Rechnung zeichenweise ausgeben.\n",
    "Es handelt sich hierbei also um *sequence to sequence learning*, da wir aus einer Eingabesequenz anschließend eine Ausgabesequenz erzeugen.\n",
    "\n",
    "Die Trainingsdaten, auf denen wir das Netz trainieren, können wir selbst erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:35:29.721959Z",
     "start_time": "2019-05-28T18:35:28.008740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, RepeatVector, TimeDistributed, Dense, Input, Lambda\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:35:29.725995Z",
     "start_time": "2019-05-28T18:35:29.723703Z"
    }
   },
   "outputs": [],
   "source": [
    "DIGITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst benötigen wir eine Klasse, welche die one-hot Kodierung und Dekodierung übernimmt.\n",
    "\n",
    "**Aufgabe**: Implementiere eine Klasse, welche zu Kodierung und Dekodierung der Eingabesequenzen verwendet werden kann. Diese soll folgende Funktionalitäten bieten:\n",
    "* Übergabe das Alphabets als Zeichenkette bei der Objekterzeugung\n",
    "* Kodierung eines Strings: Umwandlung eines Strings in eine Matrix, welche die Vektoren aus der one-hot kodierten Eingabe enthält. Zusätzlich soll eine Länge `length` angegeben werden, bis zu welcher Länge die Zeichenkette mit Leerzeichen aufgefüllt wird.\n",
    "    * Dimensionen der entstehenden Matrix: `(length, alphabet_length)`\n",
    "    * **Hinweis**: Dieses Auffüllen der Sequenz mit Leerzeichen erleichtert uns später die Erstellung des Modells. Natürlich eignen sich RNNs auch dazu Sequenzen unterschiedlicher Länge als Eingabe einzulesen, was diesen Schritt in anderen Fällen obsolet macht.\n",
    "* Dekodierung eines Vektors. Als Eingabe erhält die Funktionen einen Vektor mit den Wahrscheinlichkeiten der Auswahl der Zeichen, also einen Vektor mit `alphabet_length` Einträgen. Hier reicht es aus das Zeichen, welches mit höchster Wahrscheinlichkeit ausgewählt wird, zu ermitteln und zurückzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:35:29.748922Z",
     "start_time": "2019-05-28T18:35:29.727448Z"
    }
   },
   "outputs": [],
   "source": [
    "class OneHot(object):\n",
    "    def __init__(self, characters):\n",
    "        self.chars = sorted(set(characters))\n",
    "        self.char_to_index = dict((char, i) for i, char in enumerate(self.chars))\n",
    "        self.index_to_char = dict((i, char) for i, char in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, string, length):\n",
    "        enc = np.zeros((length, len(self.chars)))\n",
    "        for i, char in enumerate(string):\n",
    "            enc[i, self.char_to_index[char]] = 1\n",
    "        for i in range(len(string), length):\n",
    "            enc[i, self.char_to_index[' ']] = 1\n",
    "        return enc\n",
    "    \n",
    "    def decode_max(self, vec):\n",
    "        return self.index_to_char[np.argmax(vec)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erzeugung der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Training des Netzes benötigen wir Trainingsdaten, welche wir uns in ausreichender Menge selbst erstellen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Erstelle eine Funktion, welche Trainingsdaten einer bestimmten Größe für unsere Problemstellung erzeugt.\n",
    "* Per Parameter kann diese eine Anzahl Ziffern übergeben bekommen, aus denen eine Zahl maximal bestehen darf.\n",
    "* Beachte dabei: Diese Funktion gibt Zeichenketten, keine `integer` zurück\n",
    "* Es sollte keine Aufgabe mehrfach in den Daten vorkommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:35:29.761990Z",
     "start_time": "2019-05-28T18:35:29.750473Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_add(size, digits=DIGITS):\n",
    "    X = []\n",
    "    y = []\n",
    "    hist = []\n",
    "    while len(X) < size:\n",
    "        num1 = np.random.randint(low=0, high=10 ** digits - 1)\n",
    "        num2 = np.random.randint(low=0, high=10 ** digits - 1)\n",
    "        if not (num1, num2) in hist:\n",
    "            hist.append((num1, num2))\n",
    "            X.append('{}+{}'.format(num1, num2))\n",
    "            y.append(str(num1 + num2))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Erzeuge einen Datensatz mit 50000 Einträgen, welchen wir für das Training benutzen und erzeuge die One-Hot kodierte Matrix dieses Datensatzes.\n",
    "Teile diesen anschließend in 20% Validierungs- und 80% Trainingsdatensatz ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:36:14.087559Z",
     "start_time": "2019-05-28T18:35:29.763516Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = create_data_add(50000)\n",
    "\n",
    "encoder = OneHot('0123456789+ ')\n",
    "for i in range(len(X)):\n",
    "    X[i] = encoder.encode(X[i], 3 * 2 + 1)\n",
    "    y[i] = encoder.encode(y[i], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:36:14.182345Z",
     "start_time": "2019-05-28T18:36:14.090023Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train, X_val = X[:40000], X[40000:]\n",
    "y_train, y_val = y[:40000], y[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Lösung unseres Problems benötigen wir ein Sequence-to-Sequence Modell, also ein Modell, welches zunächst elementweise eine Eingabesequenz erhält und anschließend, ebenfalls elementweise, eine Ausgabesequenz ausgibt.\n",
    "Das Einlesen geschieht im Encoder (im Bild weiß), das anschließende Auswerten des sich ergebenden Zellzustandes im Decoder (grau), welche beide RNN-Zellen sind.\n",
    "Wir verwenden hier zunächst LSTM-Zellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sequence to Sequence Modell](seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir bauen dieses Modell wie folgt mit Hilfe von `Sequential` in Keras auf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:36:14.188413Z",
     "start_time": "2019-05-28T18:36:14.184669Z"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256\n",
    "EPOCHS = 50\n",
    "ALPHABET_LENGTH = len('0123456789+ ')\n",
    "MAXLEN = DIGITS * 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:36:15.123847Z",
     "start_time": "2019-05-28T18:36:14.190063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               275456    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             3084      \n",
      "=================================================================\n",
      "Total params: 803,852\n",
      "Trainable params: 803,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(MAXLEN, ALPHABET_LENGTH))) # Encoder\n",
    "model.add(RepeatVector(DIGITS + 1))  # Stellt dem RNN im nächsten Schritt die Ausgabe des vorherigen bereit\n",
    "model.add(LSTM(HIDDEN_SIZE, return_sequences=True)) # Decoder\n",
    "model.add(TimeDistributed(Dense(ALPHABET_LENGTH, activation='softmax'))) # Wendet eine `Dense` Schicht auf jede Ausgabe des Decoders an\n",
    "                                # und ermittelt mittels 'softmax'-Funktion die Auswahlwahrscheinlichkeiten der Zeichen\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben**: Trainiere das oben erstellte Netz für 50 Epochen. Denke daran einen Teil der Daten zur Validation zu verwenden.\n",
    "* Implementiere die untenstehende Funktion `train`\n",
    "* Um den Trainingsfortschritt zu beobachten soll nach jeder fünften Epoche eine Ausgabe erzeugt werden, in der zehn Einträge des **Valisierungs**datensatzes und die vom neuronalen Netz erzeugten Ausgabesequenzen visualisiert werden. Hierbei sollte auch sichtbar sein, ob die Ausgabe des Netzes korrekt war. Wer möchte kann dazu die untenstehende Klasse `colors` verwenden, um mit ANSI color codes die Ausgabe einzufärben.\n",
    "* Führe `train` aus. Plotte den Verlauf von `loss` und `accuracy`, sowohl auf dem Trainings- als auch auf dem Validierungsset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:36:15.128980Z",
     "start_time": "2019-05-28T18:36:15.125573Z"
    }
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:36:15.187877Z",
     "start_time": "2019-05-28T18:36:15.130697Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_val, y_val, encoder, epochs):\n",
    "    loss, acc, val_loss, val_acc = [], [], [], []\n",
    "    for iteration in range(1, epochs + 1):\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        hist = model.fit(X_train, y_train,\n",
    "                  batch_size=1000,\n",
    "                  epochs=1,\n",
    "                  validation_data=(X_val, y_val))\n",
    "        loss.append(hist.history['loss'])\n",
    "        acc.append(hist.history['acc'])\n",
    "        val_loss.append(hist.history['val_loss'])\n",
    "        val_acc.append(hist.history['val_acc'])\n",
    "        if iteration % 5 == 0:\n",
    "            for i in range(10):\n",
    "                ind = np.random.randint(0, X_val.shape[0])\n",
    "                rowx, rowy = X_val[ind], y_val[ind]\n",
    "                strx = ''\n",
    "                for seqx in rowx:\n",
    "                    strx += encoder.decode_max(seqx)\n",
    "                stry = ''\n",
    "                for seqy in rowy:\n",
    "                    stry += encoder.decode_max(seqy)\n",
    "                preds = model.predict_classes([[rowx]], verbose=0)\n",
    "                strpred = ''\n",
    "                for p in preds[0]:\n",
    "                    strpred += encoder.index_to_char[p]\n",
    "                if stry.strip() == strpred.strip():\n",
    "                    print('{}{} = {} ☑ {}{}'.format(colors.ok, strx, stry, strpred, colors.close))\n",
    "                else:\n",
    "                    print('{}{} = {} ☒ {}{}'.format(colors.fail, strx, stry, strpred, colors.close))\n",
    "    return loss, acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:42:47.843495Z",
     "start_time": "2019-05-28T18:36:15.189498Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 2.2209 - acc: 0.2857 - val_loss: 1.9888 - val_acc: 0.3135\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.9554 - acc: 0.3152 - val_loss: 1.9250 - val_acc: 0.3139\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.9142 - acc: 0.3161 - val_loss: 1.8988 - val_acc: 0.3139\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.8794 - acc: 0.3175 - val_loss: 1.8447 - val_acc: 0.3197\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.8085 - acc: 0.3310 - val_loss: 1.7479 - val_acc: 0.3474\n",
      "\u001b[91m972+500 = 1472 ☒ 1333\u001b[0m\n",
      "\u001b[91m758+751 = 1509 ☒ 1433\u001b[0m\n",
      "\u001b[91m662+45  = 707  ☒ 703 \u001b[0m\n",
      "\u001b[91m522+88  = 610  ☒ 100 \u001b[0m\n",
      "\u001b[91m824+981 = 1805 ☒ 1113\u001b[0m\n",
      "\u001b[91m49+639  = 688  ☒ 703 \u001b[0m\n",
      "\u001b[91m698+801 = 1499 ☒ 1321\u001b[0m\n",
      "\u001b[91m469+406 = 875  ☒ 100 \u001b[0m\n",
      "\u001b[91m356+913 = 1269 ☒ 100 \u001b[0m\n",
      "\u001b[91m356+271 = 627  ☒ 900 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.7148 - acc: 0.3617 - val_loss: 1.6653 - val_acc: 0.3793\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.6417 - acc: 0.3892 - val_loss: 1.6221 - val_acc: 0.3961\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.5795 - acc: 0.4180 - val_loss: 1.5394 - val_acc: 0.4401\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.5276 - acc: 0.4413 - val_loss: 1.4950 - val_acc: 0.4607\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.4897 - acc: 0.4549 - val_loss: 1.4742 - val_acc: 0.4593\n",
      "\u001b[91m501+739 = 1240 ☒ 1218\u001b[0m\n",
      "\u001b[91m300+237 = 537  ☒ 588 \u001b[0m\n",
      "\u001b[91m626+228 = 854  ☒ 861 \u001b[0m\n",
      "\u001b[91m417+544 = 961  ☒ 901 \u001b[0m\n",
      "\u001b[91m893+234 = 1127 ☒ 1108\u001b[0m\n",
      "\u001b[91m673+688 = 1361 ☒ 1386\u001b[0m\n",
      "\u001b[91m688+589 = 1277 ☒ 1266\u001b[0m\n",
      "\u001b[91m9+563   = 572  ☒ 518 \u001b[0m\n",
      "\u001b[91m778+129 = 907  ☒ 901 \u001b[0m\n",
      "\u001b[91m148+958 = 1106 ☒ 1008\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.4568 - acc: 0.4686 - val_loss: 1.4416 - val_acc: 0.4740\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.4364 - acc: 0.4750 - val_loss: 1.4171 - val_acc: 0.4883\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.4232 - acc: 0.4770 - val_loss: 1.4087 - val_acc: 0.4851\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.3888 - acc: 0.4958 - val_loss: 1.3739 - val_acc: 0.5018\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.3767 - acc: 0.4969 - val_loss: 1.3582 - val_acc: 0.5034\n",
      "\u001b[91m258+128 = 386  ☒ 499 \u001b[0m\n",
      "\u001b[91m988+510 = 1498 ☒ 1410\u001b[0m\n",
      "\u001b[91m184+648 = 832  ☒ 809 \u001b[0m\n",
      "\u001b[91m356+271 = 627  ☒ 610 \u001b[0m\n",
      "\u001b[91m163+2   = 165  ☒ 12  \u001b[0m\n",
      "\u001b[91m678+689 = 1367 ☒ 1366\u001b[0m\n",
      "\u001b[91m677+933 = 1610 ☒ 1500\u001b[0m\n",
      "\u001b[91m363+208 = 571  ☒ 610 \u001b[0m\n",
      "\u001b[91m417+448 = 865  ☒ 899 \u001b[0m\n",
      "\u001b[91m873+848 = 1721 ☒ 1703\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.3617 - acc: 0.5002 - val_loss: 1.3725 - val_acc: 0.4856\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.3380 - acc: 0.5106 - val_loss: 1.3424 - val_acc: 0.5015\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.3332 - acc: 0.5099 - val_loss: 1.2984 - val_acc: 0.5264\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.2861 - acc: 0.5354 - val_loss: 1.2729 - val_acc: 0.5394\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.2574 - acc: 0.5454 - val_loss: 1.2432 - val_acc: 0.5500\n",
      "\u001b[91m784+984 = 1768 ☒ 1766\u001b[0m\n",
      "\u001b[91m197+912 = 1109 ☒ 1110\u001b[0m\n",
      "\u001b[91m607+698 = 1305 ☒ 1266\u001b[0m\n",
      "\u001b[91m239+710 = 949  ☒ 957 \u001b[0m\n",
      "\u001b[91m833+980 = 1813 ☒ 1822\u001b[0m\n",
      "\u001b[91m429+213 = 642  ☒ 649 \u001b[0m\n",
      "\u001b[91m696+461 = 1157 ☒ 1146\u001b[0m\n",
      "\u001b[91m129+315 = 444  ☒ 447 \u001b[0m\n",
      "\u001b[91m257+115 = 372  ☒ 479 \u001b[0m\n",
      "\u001b[91m790+923 = 1713 ☒ 1724\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.2096 - acc: 0.5627 - val_loss: 1.1893 - val_acc: 0.5672\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.1641 - acc: 0.5768 - val_loss: 1.2225 - val_acc: 0.5388\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.1150 - acc: 0.5948 - val_loss: 1.0672 - val_acc: 0.6165\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.0299 - acc: 0.6350 - val_loss: 0.9967 - val_acc: 0.6378\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.9593 - acc: 0.6658 - val_loss: 0.9175 - val_acc: 0.6708\n",
      "\u001b[92m416+465 = 881  ☑ 881 \u001b[0m\n",
      "\u001b[91m9+563   = 572  ☒ 655 \u001b[0m\n",
      "\u001b[91m974+515 = 1489 ☒ 1599\u001b[0m\n",
      "\u001b[91m745+551 = 1296 ☒ 1398\u001b[0m\n",
      "\u001b[92m387+457 = 844  ☑ 844 \u001b[0m\n",
      "\u001b[91m981+645 = 1626 ☒ 1628\u001b[0m\n",
      "\u001b[92m596+275 = 871  ☑ 871 \u001b[0m\n",
      "\u001b[92m732+340 = 1072 ☑ 1072\u001b[0m\n",
      "\u001b[91m313+714 = 1027 ☒ 1048\u001b[0m\n",
      "\u001b[91m719+243 = 962  ☒ 961 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.8741 - acc: 0.7039 - val_loss: 0.8354 - val_acc: 0.7141\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.8032 - acc: 0.7316 - val_loss: 0.7556 - val_acc: 0.7578\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.7353 - acc: 0.7641 - val_loss: 0.7149 - val_acc: 0.7497\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.6865 - acc: 0.7826 - val_loss: 0.6644 - val_acc: 0.7862\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.6390 - acc: 0.8026 - val_loss: 0.6108 - val_acc: 0.8223\n",
      "\u001b[92m730+568 = 1298 ☑ 1298\u001b[0m\n",
      "\u001b[92m754+966 = 1720 ☑ 1720\u001b[0m\n",
      "\u001b[92m373+253 = 626  ☑ 626 \u001b[0m\n",
      "\u001b[92m975+290 = 1265 ☑ 1265\u001b[0m\n",
      "\u001b[91m876+64  = 940  ☒ 762 \u001b[0m\n",
      "\u001b[92m938+603 = 1541 ☑ 1541\u001b[0m\n",
      "\u001b[92m118+433 = 551  ☑ 551 \u001b[0m\n",
      "\u001b[91m128+193 = 321  ☒ 311 \u001b[0m\n",
      "\u001b[92m572+984 = 1556 ☑ 1556\u001b[0m\n",
      "\u001b[91m22+256  = 278  ☒ 267 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.5980 - acc: 0.8205 - val_loss: 0.5763 - val_acc: 0.8327\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.5669 - acc: 0.8292 - val_loss: 0.5537 - val_acc: 0.8340\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.5496 - acc: 0.8297 - val_loss: 0.5362 - val_acc: 0.8360\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.5139 - acc: 0.8463 - val_loss: 0.4950 - val_acc: 0.8533\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.4823 - acc: 0.8567 - val_loss: 0.4709 - val_acc: 0.8617\n",
      "\u001b[91m159+303 = 462  ☒ 452 \u001b[0m\n",
      "\u001b[92m778+474 = 1252 ☑ 1252\u001b[0m\n",
      "\u001b[92m898+646 = 1544 ☑ 1544\u001b[0m\n",
      "\u001b[91m75+425  = 500  ☒ 510 \u001b[0m\n",
      "\u001b[92m431+869 = 1300 ☑ 1300\u001b[0m\n",
      "\u001b[91m96+220  = 316  ☒ 208 \u001b[0m\n",
      "\u001b[92m257+375 = 632  ☑ 632 \u001b[0m\n",
      "\u001b[91m186+803 = 989  ☒ 999 \u001b[0m\n",
      "\u001b[91m49+937  = 986  ☒ 904 \u001b[0m\n",
      "\u001b[92m844+870 = 1714 ☑ 1714\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.4669 - acc: 0.8588 - val_loss: 0.4514 - val_acc: 0.8618\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.4479 - acc: 0.8635 - val_loss: 0.4453 - val_acc: 0.8603\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.4281 - acc: 0.8690 - val_loss: 0.4159 - val_acc: 0.8703\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.4131 - acc: 0.8722 - val_loss: 0.4075 - val_acc: 0.8751\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.3995 - acc: 0.8757 - val_loss: 0.3928 - val_acc: 0.8746\n",
      "\u001b[91m81+71   = 152  ☒ 119 \u001b[0m\n",
      "\u001b[91m509+8   = 517  ☒ 109 \u001b[0m\n",
      "\u001b[91m64+129  = 193  ☒ 204 \u001b[0m\n",
      "\u001b[92m438+138 = 576  ☑ 576 \u001b[0m\n",
      "\u001b[91m444+957 = 1401 ☒ 1301\u001b[0m\n",
      "\u001b[91m373+29  = 402  ☒ 312 \u001b[0m\n",
      "\u001b[91m885+555 = 1440 ☒ 1430\u001b[0m\n",
      "\u001b[91m18+521  = 539  ☒ 249 \u001b[0m\n",
      "\u001b[92m563+953 = 1516 ☑ 1516\u001b[0m\n",
      "\u001b[92m648+585 = 1233 ☑ 1233\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.3849 - acc: 0.8791 - val_loss: 0.3822 - val_acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.3759 - acc: 0.8812 - val_loss: 0.3807 - val_acc: 0.8785\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3779 - acc: 0.8779 - val_loss: 0.3672 - val_acc: 0.8795\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.3552 - acc: 0.8853 - val_loss: 0.3531 - val_acc: 0.8823\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.3441 - acc: 0.8880 - val_loss: 0.3633 - val_acc: 0.8720\n",
      "\u001b[91m757+24  = 781  ☒ 799 \u001b[0m\n",
      "\u001b[92m847+714 = 1561 ☑ 1561\u001b[0m\n",
      "\u001b[92m412+161 = 573  ☑ 573 \u001b[0m\n",
      "\u001b[92m745+517 = 1262 ☑ 1262\u001b[0m\n",
      "\u001b[92m659+847 = 1506 ☑ 1506\u001b[0m\n",
      "\u001b[92m711+866 = 1577 ☑ 1577\u001b[0m\n",
      "\u001b[91m107+982 = 1089 ☒ 1099\u001b[0m\n",
      "\u001b[91m980+101 = 1081 ☒ 1181\u001b[0m\n",
      "\u001b[92m102+558 = 660  ☑ 660 \u001b[0m\n",
      "\u001b[92m165+846 = 1011 ☑ 1011\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3401 - acc: 0.8878 - val_loss: 0.3356 - val_acc: 0.8903\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3242 - acc: 0.8935 - val_loss: 0.3252 - val_acc: 0.8916\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.3140 - acc: 0.8968 - val_loss: 0.3147 - val_acc: 0.8959\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.3065 - acc: 0.8980 - val_loss: 0.3119 - val_acc: 0.8962\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3011 - acc: 0.8993 - val_loss: 0.3021 - val_acc: 0.8992\n",
      "\u001b[92m961+884 = 1845 ☑ 1845\u001b[0m\n",
      "\u001b[92m622+395 = 1017 ☑ 1017\u001b[0m\n",
      "\u001b[92m165+903 = 1068 ☑ 1068\u001b[0m\n",
      "\u001b[92m540+782 = 1322 ☑ 1322\u001b[0m\n",
      "\u001b[92m35+976  = 1011 ☑ 1011\u001b[0m\n",
      "\u001b[92m550+840 = 1390 ☑ 1390\u001b[0m\n",
      "\u001b[92m899+316 = 1215 ☑ 1215\u001b[0m\n",
      "\u001b[92m627+395 = 1022 ☑ 1022\u001b[0m\n",
      "\u001b[91m172+778 = 950  ☒ 940 \u001b[0m\n",
      "\u001b[92m365+575 = 940  ☑ 940 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loss, acc, val_loss, val_acc = train(model, X_train, y_train, X_val, y_val, encoder, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:42:48.070275Z",
     "start_time": "2019-05-28T18:42:47.845912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00481fd8d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='validation loss')\n",
    "plt.plot(acc, label='accuracy')\n",
    "plt.plot(val_acc, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtraktion statt Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Wir werden nun das oben stehende Netz auf Subtraktion statt Addition trainieren.\n",
    "Implementiere dazu eine Funktion oder ändere die obenstehende ab, um entsprechende Trainingsdaten zu erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:42:48.085279Z",
     "start_time": "2019-05-28T18:42:48.072008Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_sub(size, digits=3):\n",
    "    X = []\n",
    "    y = []\n",
    "    hist = []\n",
    "    while len(X) < size:\n",
    "        num1 = np.random.randint(low=0, high=10 ** digits - 1)\n",
    "        num2 = np.random.randint(low=0, high=10 ** digits - 1)\n",
    "        if not (num1, num2) in hist:\n",
    "            hist.append((num1, num2))\n",
    "            X.append('{}-{}'.format(num1, num2))\n",
    "            y.append(str(num1 - num2))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Erzeuge wie oben einen Datensatz und One-Hot-Kodiere ihn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:43:32.402751Z",
     "start_time": "2019-05-28T18:42:48.087022Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = create_data_sub(50000)\n",
    "\n",
    "encoder_sub = OneHot('0123456789- ')\n",
    "for i in range(len(X)):\n",
    "    X[i] = encoder_sub.encode(X[i], 3 * 2 + 1)\n",
    "    y[i] = encoder_sub.encode(y[i], 4)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train_sub, X_val_sub = X[:40000], X[40000:]\n",
    "y_train_sub, y_val_sub = y[:40000], y[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Trainiere sowohl ein \"frisches\", untrainiertes Netz so wie eine Kopie des zuvor auf die Addition trainierten Netzes wie oben beschrieben und vergleiche den Trainingserfolg. Was fällt auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:56:46.199945Z",
     "start_time": "2019-05-28T18:43:32.405016Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 3.1734 - acc: 0.2148 - val_loss: 2.1338 - val_acc: 0.2430\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 2.0324 - acc: 0.2945 - val_loss: 1.9388 - val_acc: 0.3370\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.8689 - acc: 0.3472 - val_loss: 1.8130 - val_acc: 0.3584\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.7493 - acc: 0.3727 - val_loss: 1.6905 - val_acc: 0.3920\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.6326 - acc: 0.4150 - val_loss: 1.5766 - val_acc: 0.4324\n",
      "\u001b[91m310-475 = -165 ☒ -14 \u001b[0m\n",
      "\u001b[91m840-9   = 831  ☒ -4  \u001b[0m\n",
      "\u001b[91m472-408 = 64   ☒ 12  \u001b[0m\n",
      "\u001b[91m569-307 = 262  ☒ 21  \u001b[0m\n",
      "\u001b[91m505-194 = 311  ☒ 110 \u001b[0m\n",
      "\u001b[91m906-501 = 405  ☒ 100 \u001b[0m\n",
      "\u001b[91m687-806 = -119 ☒ -10 \u001b[0m\n",
      "\u001b[91m333-854 = -521 ☒ -409\u001b[0m\n",
      "\u001b[91m684-880 = -196 ☒ -10 \u001b[0m\n",
      "\u001b[91m850-759 = 91   ☒ -1  \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.5145 - acc: 0.4606 - val_loss: 1.4720 - val_acc: 0.4751\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.4343 - acc: 0.4864 - val_loss: 1.3913 - val_acc: 0.5006\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.3432 - acc: 0.5172 - val_loss: 1.3115 - val_acc: 0.5229\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.2874 - acc: 0.5312 - val_loss: 1.2594 - val_acc: 0.5376\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.2139 - acc: 0.5560 - val_loss: 1.2116 - val_acc: 0.5526\n",
      "\u001b[91m696-764 = -68  ☒ -10 \u001b[0m\n",
      "\u001b[91m11-896  = -885 ☒ -777\u001b[0m\n",
      "\u001b[91m698-870 = -172 ☒ -101\u001b[0m\n",
      "\u001b[91m509-222 = 287  ☒ 277 \u001b[0m\n",
      "\u001b[91m370-742 = -372 ☒ -332\u001b[0m\n",
      "\u001b[91m997-27  = 970  ☒ 770 \u001b[0m\n",
      "\u001b[91m77-741  = -664 ☒ -684\u001b[0m\n",
      "\u001b[91m549-544 = 5    ☒ -1  \u001b[0m\n",
      "\u001b[91m812-11  = 801  ☒ 790 \u001b[0m\n",
      "\u001b[91m846-502 = 344  ☒ 352 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.1539 - acc: 0.5758 - val_loss: 1.1230 - val_acc: 0.5801\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.0926 - acc: 0.5964 - val_loss: 1.1069 - val_acc: 0.5825\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.0256 - acc: 0.6210 - val_loss: 1.0242 - val_acc: 0.6148\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.9702 - acc: 0.6423 - val_loss: 0.9792 - val_acc: 0.6258\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.9172 - acc: 0.6601 - val_loss: 0.8983 - val_acc: 0.6650\n",
      "\u001b[91m705-824 = -119 ☒ -109\u001b[0m\n",
      "\u001b[92m454-758 = -304 ☑ -304\u001b[0m\n",
      "\u001b[91m222-61  = 161  ☒ 181 \u001b[0m\n",
      "\u001b[91m515-840 = -325 ☒ -316\u001b[0m\n",
      "\u001b[91m621-917 = -296 ☒ -297\u001b[0m\n",
      "\u001b[91m474-4   = 470  ☒ 56  \u001b[0m\n",
      "\u001b[91m99-387  = -288 ☒ -188\u001b[0m\n",
      "\u001b[92m539-884 = -345 ☑ -345\u001b[0m\n",
      "\u001b[91m219-171 = 48   ☒ 15  \u001b[0m\n",
      "\u001b[92m835-323 = 512  ☑ 512 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.8613 - acc: 0.6827 - val_loss: 0.8380 - val_acc: 0.6902\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.7869 - acc: 0.7171 - val_loss: 0.7632 - val_acc: 0.7235\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.7343 - acc: 0.7376 - val_loss: 0.7081 - val_acc: 0.7481\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.6849 - acc: 0.7599 - val_loss: 0.6897 - val_acc: 0.7512\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.6293 - acc: 0.7876 - val_loss: 0.6230 - val_acc: 0.7831\n",
      "\u001b[92m199-435 = -236 ☑ -236\u001b[0m\n",
      "\u001b[92m299-688 = -389 ☑ -389\u001b[0m\n",
      "\u001b[92m996-468 = 528  ☑ 528 \u001b[0m\n",
      "\u001b[91m959-926 = 33   ☒ 43  \u001b[0m\n",
      "\u001b[92m223-942 = -719 ☑ -719\u001b[0m\n",
      "\u001b[91m665-964 = -299 ☒ -399\u001b[0m\n",
      "\u001b[92m478-268 = 210  ☑ 210 \u001b[0m\n",
      "\u001b[91m21-614  = -593 ☒ -692\u001b[0m\n",
      "\u001b[91m204-190 = 14   ☒ -   \u001b[0m\n",
      "\u001b[91m283-72  = 211  ☒ 122 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.5928 - acc: 0.8018 - val_loss: 0.5906 - val_acc: 0.7940\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.5500 - acc: 0.8212 - val_loss: 0.5477 - val_acc: 0.8200\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.5242 - acc: 0.8291 - val_loss: 0.5308 - val_acc: 0.8206\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.6455 - acc: 0.7670 - val_loss: 0.5497 - val_acc: 0.8092\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.4878 - acc: 0.8444 - val_loss: 0.4796 - val_acc: 0.8447\n",
      "\u001b[92m399-645 = -246 ☑ -246\u001b[0m\n",
      "\u001b[91m535-299 = 236  ☒ 246 \u001b[0m\n",
      "\u001b[92m505-617 = -112 ☑ -112\u001b[0m\n",
      "\u001b[92m706-909 = -203 ☑ -203\u001b[0m\n",
      "\u001b[92m560-427 = 133  ☑ 133 \u001b[0m\n",
      "\u001b[92m743-198 = 545  ☑ 545 \u001b[0m\n",
      "\u001b[91m130-65  = 65   ☒ 16  \u001b[0m\n",
      "\u001b[92m545-177 = 368  ☑ 368 \u001b[0m\n",
      "\u001b[91m322-821 = -499 ☒ -599\u001b[0m\n",
      "\u001b[92m748-954 = -206 ☑ -206\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.4525 - acc: 0.8588 - val_loss: 0.4606 - val_acc: 0.8503\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.4317 - acc: 0.8669 - val_loss: 0.4410 - val_acc: 0.8563\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.4155 - acc: 0.8720 - val_loss: 0.4256 - val_acc: 0.8608\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3983 - acc: 0.8782 - val_loss: 0.4098 - val_acc: 0.8688\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.3847 - acc: 0.8819 - val_loss: 0.3995 - val_acc: 0.8707\n",
      "\u001b[92m529-154 = 375  ☑ 375 \u001b[0m\n",
      "\u001b[92m811-881 = -70  ☑ -70 \u001b[0m\n",
      "\u001b[91m803-41  = 762  ☒ 860 \u001b[0m\n",
      "\u001b[92m736-475 = 261  ☑ 261 \u001b[0m\n",
      "\u001b[92m757-410 = 347  ☑ 347 \u001b[0m\n",
      "\u001b[91m370-250 = 120  ☒ 110 \u001b[0m\n",
      "\u001b[91m677-635 = 42   ☒ 53  \u001b[0m\n",
      "\u001b[91m613-26  = 587  ☒ 597 \u001b[0m\n",
      "\u001b[92m311-826 = -515 ☑ -515\u001b[0m\n",
      "\u001b[92m550-845 = -295 ☑ -295\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 0.3694 - acc: 0.8871 - val_loss: 0.3783 - val_acc: 0.8807\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.3565 - acc: 0.8912 - val_loss: 0.3792 - val_acc: 0.8766\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3395 - acc: 0.8996 - val_loss: 0.3507 - val_acc: 0.8882\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.3283 - acc: 0.9023 - val_loss: 0.3554 - val_acc: 0.8815\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.3288 - acc: 0.8988 - val_loss: 0.3462 - val_acc: 0.8886\n",
      "\u001b[91m977-795 = 182  ☒ 192 \u001b[0m\n",
      "\u001b[92m240-967 = -727 ☑ -727\u001b[0m\n",
      "\u001b[91m979-797 = 182  ☒ 192 \u001b[0m\n",
      "\u001b[92m608-436 = 172  ☑ 172 \u001b[0m\n",
      "\u001b[92m287-662 = -375 ☑ -375\u001b[0m\n",
      "\u001b[92m313-141 = 172  ☑ 172 \u001b[0m\n",
      "\u001b[92m910-536 = 374  ☑ 374 \u001b[0m\n",
      "\u001b[91m654-514 = 140  ☒ 130 \u001b[0m\n",
      "\u001b[92m22-142  = -120 ☑ -120\u001b[0m\n",
      "\u001b[91m784-746 = 38   ☒ 47  \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.3111 - acc: 0.9069 - val_loss: 0.3221 - val_acc: 0.8976\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.2983 - acc: 0.9122 - val_loss: 0.3330 - val_acc: 0.8878\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 0.2894 - acc: 0.9141 - val_loss: 0.3099 - val_acc: 0.8999\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.2792 - acc: 0.9183 - val_loss: 0.2909 - val_acc: 0.9086\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.2685 - acc: 0.9225 - val_loss: 0.2876 - val_acc: 0.9104\n",
      "\u001b[92m326-553 = -227 ☑ -227\u001b[0m\n",
      "\u001b[92m431-875 = -444 ☑ -444\u001b[0m\n",
      "\u001b[92m305-914 = -609 ☑ -609\u001b[0m\n",
      "\u001b[92m34-335  = -301 ☑ -301\u001b[0m\n",
      "\u001b[92m758-484 = 274  ☑ 274 \u001b[0m\n",
      "\u001b[92m961-524 = 437  ☑ 437 \u001b[0m\n",
      "\u001b[92m249-351 = -102 ☑ -102\u001b[0m\n",
      "\u001b[91m21-614  = -593 ☒ -693\u001b[0m\n",
      "\u001b[92m446-924 = -478 ☑ -478\u001b[0m\n",
      "\u001b[91m925-826 = 99   ☒ 10  \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.2635 - acc: 0.9234 - val_loss: 0.2821 - val_acc: 0.9098\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.2544 - acc: 0.9263 - val_loss: 0.2743 - val_acc: 0.9136\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.2446 - acc: 0.9303 - val_loss: 0.2597 - val_acc: 0.9201\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.2405 - acc: 0.9311 - val_loss: 0.2608 - val_acc: 0.9169\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.2338 - acc: 0.9329 - val_loss: 0.2531 - val_acc: 0.9204\n",
      "\u001b[91m566-49  = 517  ☒ 597 \u001b[0m\n",
      "\u001b[92m33-543  = -510 ☑ -510\u001b[0m\n",
      "\u001b[92m849-590 = 259  ☑ 259 \u001b[0m\n",
      "\u001b[91m116-47  = 69   ☒ 17  \u001b[0m\n",
      "\u001b[92m365-638 = -273 ☑ -273\u001b[0m\n",
      "\u001b[92m108-445 = -337 ☑ -337\u001b[0m\n",
      "\u001b[91m956-961 = -5   ☒ -   \u001b[0m\n",
      "\u001b[91m709-646 = 63   ☒ 53  \u001b[0m\n",
      "\u001b[91m475-68  = 407  ☒ 417 \u001b[0m\n",
      "\u001b[92m520-373 = 147  ☑ 147 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.2256 - acc: 0.9363 - val_loss: 0.2470 - val_acc: 0.9240\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.2215 - acc: 0.9370 - val_loss: 0.2471 - val_acc: 0.9216\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.7932 - acc: 0.7710 - val_loss: 0.4016 - val_acc: 0.8602\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 0.2886 - acc: 0.9143 - val_loss: 0.2583 - val_acc: 0.9232\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.2234 - acc: 0.9414 - val_loss: 0.2364 - val_acc: 0.9303\n",
      "\u001b[92m132-946 = -814 ☑ -814\u001b[0m\n",
      "\u001b[92m789-959 = -170 ☑ -170\u001b[0m\n",
      "\u001b[92m782-751 = 31   ☑ 31  \u001b[0m\n",
      "\u001b[92m745-832 = -87  ☑ -87 \u001b[0m\n",
      "\u001b[91m469-62  = 407  ☒ 307 \u001b[0m\n",
      "\u001b[92m521-853 = -332 ☑ -332\u001b[0m\n",
      "\u001b[92m733-911 = -178 ☑ -178\u001b[0m\n",
      "\u001b[92m993-511 = 482  ☑ 482 \u001b[0m\n",
      "\u001b[92m70-735  = -665 ☑ -665\u001b[0m\n",
      "\u001b[92m996-275 = 721  ☑ 721 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 2.3180 - acc: 0.2032 - val_loss: 2.1908 - val_acc: 0.3382\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 2.0306 - acc: 0.3351 - val_loss: 1.9426 - val_acc: 0.3357\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.8897 - acc: 0.3402 - val_loss: 1.8674 - val_acc: 0.3480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.8165 - acc: 0.3535 - val_loss: 1.7902 - val_acc: 0.3568\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.7515 - acc: 0.3755 - val_loss: 1.7118 - val_acc: 0.3892\n",
      "\u001b[91m593-567 = 26   ☒ 11  \u001b[0m\n",
      "\u001b[91m574-761 = -187 ☒ -1  \u001b[0m\n",
      "\u001b[91m137-16  = 121  ☒ 21  \u001b[0m\n",
      "\u001b[91m33-353  = -320 ☒ -411\u001b[0m\n",
      "\u001b[91m910-521 = 389  ☒ 316 \u001b[0m\n",
      "\u001b[91m734-672 = 62   ☒ -1  \u001b[0m\n",
      "\u001b[91m71-482  = -411 ☒ -489\u001b[0m\n",
      "\u001b[91m448-474 = -26  ☒ -12 \u001b[0m\n",
      "\u001b[91m461-347 = 114  ☒ 11  \u001b[0m\n",
      "\u001b[91m629-97  = 532  ☒ -1  \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.6956 - acc: 0.3913 - val_loss: 1.6649 - val_acc: 0.3998\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.6626 - acc: 0.4014 - val_loss: 1.6919 - val_acc: 0.3890\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.6251 - acc: 0.4148 - val_loss: 1.5979 - val_acc: 0.4283\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.5949 - acc: 0.4268 - val_loss: 1.5632 - val_acc: 0.4452\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.5628 - acc: 0.4417 - val_loss: 1.5270 - val_acc: 0.4622\n",
      "\u001b[91m314-349 = -35  ☒ -1  \u001b[0m\n",
      "\u001b[91m15-782  = -767 ☒ -729\u001b[0m\n",
      "\u001b[91m396-208 = 188  ☒ 115 \u001b[0m\n",
      "\u001b[91m340-567 = -227 ☒ -222\u001b[0m\n",
      "\u001b[91m563-365 = 198  ☒ 212 \u001b[0m\n",
      "\u001b[91m944-176 = 768  ☒ 511 \u001b[0m\n",
      "\u001b[91m776-693 = 83   ☒ 11  \u001b[0m\n",
      "\u001b[91m722-136 = 586  ☒ 515 \u001b[0m\n",
      "\u001b[92m800-19  = 781  ☑ 781 \u001b[0m\n",
      "\u001b[91m668-638 = 30   ☒ -1  \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 1.5436 - acc: 0.4471 - val_loss: 1.5053 - val_acc: 0.4659\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.5081 - acc: 0.4591 - val_loss: 1.4775 - val_acc: 0.4763\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.4734 - acc: 0.4752 - val_loss: 1.4579 - val_acc: 0.4796\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.4606 - acc: 0.4748 - val_loss: 1.4601 - val_acc: 0.4680\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.4352 - acc: 0.4837 - val_loss: 1.4189 - val_acc: 0.4866\n",
      "\u001b[91m786-782 = 4    ☒ -1  \u001b[0m\n",
      "\u001b[91m711-309 = 402  ☒ 377 \u001b[0m\n",
      "\u001b[91m964-633 = 331  ☒ 327 \u001b[0m\n",
      "\u001b[91m50-48   = 2    ☒ -1  \u001b[0m\n",
      "\u001b[91m516-543 = -27  ☒ -1  \u001b[0m\n",
      "\u001b[91m57-454  = -397 ☒ -466\u001b[0m\n",
      "\u001b[91m769-875 = -106 ☒ -10 \u001b[0m\n",
      "\u001b[91m179-939 = -760 ☒ -720\u001b[0m\n",
      "\u001b[91m277-529 = -252 ☒ -206\u001b[0m\n",
      "\u001b[91m417-17  = 400  ☒ 477 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.4250 - acc: 0.4853 - val_loss: 1.4023 - val_acc: 0.4939\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.4064 - acc: 0.4898 - val_loss: 1.4058 - val_acc: 0.4867\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.3880 - acc: 0.4972 - val_loss: 1.4051 - val_acc: 0.4835\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.3815 - acc: 0.4980 - val_loss: 1.3637 - val_acc: 0.5019\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.3696 - acc: 0.5004 - val_loss: 1.3542 - val_acc: 0.5050\n",
      "\u001b[91m185-435 = -250 ☒ -288\u001b[0m\n",
      "\u001b[91m33-784  = -751 ☒ -846\u001b[0m\n",
      "\u001b[91m705-990 = -285 ☒ -388\u001b[0m\n",
      "\u001b[91m276-457 = -181 ☒ -184\u001b[0m\n",
      "\u001b[91m891-880 = 11   ☒ -1  \u001b[0m\n",
      "\u001b[91m196-652 = -456 ☒ -488\u001b[0m\n",
      "\u001b[91m904-559 = 345  ☒ 311 \u001b[0m\n",
      "\u001b[91m300-795 = -495 ☒ -455\u001b[0m\n",
      "\u001b[91m110-411 = -301 ☒ -311\u001b[0m\n",
      "\u001b[91m720-921 = -201 ☒ -284\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.3433 - acc: 0.5099 - val_loss: 1.3311 - val_acc: 0.5140\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 1.3449 - acc: 0.5082 - val_loss: 1.3219 - val_acc: 0.5118\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.3207 - acc: 0.5166 - val_loss: 1.3094 - val_acc: 0.5194\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.3154 - acc: 0.5179 - val_loss: 1.2979 - val_acc: 0.5224\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.2988 - acc: 0.5246 - val_loss: 1.2998 - val_acc: 0.5185\n",
      "\u001b[91m214-568 = -354 ☒ -333\u001b[0m\n",
      "\u001b[91m865-337 = 528  ☒ 533 \u001b[0m\n",
      "\u001b[91m623-962 = -339 ☒ -311\u001b[0m\n",
      "\u001b[91m454-622 = -168 ☒ -160\u001b[0m\n",
      "\u001b[91m981-799 = 182  ☒ 100 \u001b[0m\n",
      "\u001b[91m322-977 = -655 ☒ -644\u001b[0m\n",
      "\u001b[91m727-663 = 64   ☒ 11  \u001b[0m\n",
      "\u001b[91m493-507 = -14  ☒ -10 \u001b[0m\n",
      "\u001b[91m622-535 = 87   ☒ 11  \u001b[0m\n",
      "\u001b[91m818-607 = 211  ☒ 112 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.2793 - acc: 0.5321 - val_loss: 1.2808 - val_acc: 0.5300\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.2923 - acc: 0.5244 - val_loss: 1.2657 - val_acc: 0.5337\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.2643 - acc: 0.5357 - val_loss: 1.3171 - val_acc: 0.5183\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.2432 - acc: 0.5437 - val_loss: 1.2554 - val_acc: 0.5327\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.2238 - acc: 0.5514 - val_loss: 1.2435 - val_acc: 0.5412\n",
      "\u001b[91m812-11  = 801  ☒ 709 \u001b[0m\n",
      "\u001b[91m800-360 = 440  ☒ 400 \u001b[0m\n",
      "\u001b[91m831-860 = -29  ☒ -2  \u001b[0m\n",
      "\u001b[91m103-903 = -800 ☒ -797\u001b[0m\n",
      "\u001b[91m878-81  = 797  ☒ 777 \u001b[0m\n",
      "\u001b[91m135-364 = -229 ☒ -220\u001b[0m\n",
      "\u001b[91m874-496 = 378  ☒ 489 \u001b[0m\n",
      "\u001b[91m701-9   = 692  ☒ 747 \u001b[0m\n",
      "\u001b[91m4-425   = -421 ☒ -444\u001b[0m\n",
      "\u001b[91m939-114 = 825  ☒ 750 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.2238 - acc: 0.5494 - val_loss: 1.2218 - val_acc: 0.5422\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 1.2019 - acc: 0.5556 - val_loss: 1.2017 - val_acc: 0.5514\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 198us/step - loss: 1.1862 - acc: 0.5620 - val_loss: 1.2122 - val_acc: 0.5403\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 197us/step - loss: 1.1611 - acc: 0.5692 - val_loss: 1.1414 - val_acc: 0.5720\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.1270 - acc: 0.5826 - val_loss: 1.1148 - val_acc: 0.5808\n",
      "\u001b[91m825-699 = 126  ☒ 133 \u001b[0m\n",
      "\u001b[91m802-307 = 495  ☒ 431 \u001b[0m\n",
      "\u001b[91m553-476 = 77   ☒ 16  \u001b[0m\n",
      "\u001b[91m619-940 = -321 ☒ -322\u001b[0m\n",
      "\u001b[91m203-426 = -223 ☒ -224\u001b[0m\n",
      "\u001b[91m309-187 = 122  ☒ 121 \u001b[0m\n",
      "\u001b[91m746-456 = 290  ☒ 281 \u001b[0m\n",
      "\u001b[91m687-657 = 30   ☒ 11  \u001b[0m\n",
      "\u001b[91m261-213 = 48   ☒ 13  \u001b[0m\n",
      "\u001b[91m158-663 = -505 ☒ -506\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.0913 - acc: 0.5958 - val_loss: 1.0971 - val_acc: 0.5955\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.0542 - acc: 0.6114 - val_loss: 1.0469 - val_acc: 0.6147\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 1.0212 - acc: 0.6275 - val_loss: 1.0143 - val_acc: 0.6292\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.9948 - acc: 0.6377 - val_loss: 0.9948 - val_acc: 0.6354\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.9696 - acc: 0.6478 - val_loss: 0.9682 - val_acc: 0.6387\n",
      "\u001b[91m301-954 = -653 ☒ -642\u001b[0m\n",
      "\u001b[91m743-542 = 201  ☒ 101 \u001b[0m\n",
      "\u001b[91m828-409 = 419  ☒ 411 \u001b[0m\n",
      "\u001b[91m975-903 = 72   ☒ 55  \u001b[0m\n",
      "\u001b[91m402-203 = 199  ☒ 191 \u001b[0m\n",
      "\u001b[91m228-52  = 176  ☒ 106 \u001b[0m\n",
      "\u001b[91m623-390 = 233  ☒ 241 \u001b[0m\n",
      "\u001b[91m961-480 = 481  ☒ 581 \u001b[0m\n",
      "\u001b[91m171-906 = -735 ☒ -721\u001b[0m\n",
      "\u001b[91m883-888 = -5   ☒ -   \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.9279 - acc: 0.6646 - val_loss: 0.9314 - val_acc: 0.6618\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.8845 - acc: 0.6793 - val_loss: 0.8601 - val_acc: 0.6944\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.1506 - acc: 0.5850 - val_loss: 1.0419 - val_acc: 0.5991\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.8704 - acc: 0.6866 - val_loss: 0.8017 - val_acc: 0.7188\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.7488 - acc: 0.7511 - val_loss: 0.7366 - val_acc: 0.7510\n",
      "\u001b[92m688-509 = 179  ☑ 179 \u001b[0m\n",
      "\u001b[92m637-104 = 533  ☑ 533 \u001b[0m\n",
      "\u001b[91m715-702 = 13   ☒ 11  \u001b[0m\n",
      "\u001b[91m836-846 = -10  ☒ -1  \u001b[0m\n",
      "\u001b[91m633-938 = -305 ☒ -314\u001b[0m\n",
      "\u001b[91m411-345 = 66   ☒ 75  \u001b[0m\n",
      "\u001b[91m319-542 = -223 ☒ -224\u001b[0m\n",
      "\u001b[91m979-318 = 661  ☒ 660 \u001b[0m\n",
      "\u001b[91m924-605 = 319  ☒ 318 \u001b[0m\n",
      "\u001b[91m556-925 = -369 ☒ -378\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 196us/step - loss: 0.6952 - acc: 0.7715 - val_loss: 0.6791 - val_acc: 0.7793\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.6533 - acc: 0.7843 - val_loss: 0.6786 - val_acc: 0.7401\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.6203 - acc: 0.7941 - val_loss: 0.6055 - val_acc: 0.8055\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.5758 - acc: 0.8194 - val_loss: 0.5687 - val_acc: 0.8191\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.5700 - acc: 0.8068 - val_loss: 0.5419 - val_acc: 0.8275\n",
      "\u001b[91m588-683 = -95  ☒ -96 \u001b[0m\n",
      "\u001b[91m297-96  = 201  ☒ 182 \u001b[0m\n",
      "\u001b[92m903-620 = 283  ☑ 283 \u001b[0m\n",
      "\u001b[91m330-283 = 47   ☒ 43  \u001b[0m\n",
      "\u001b[91m623-271 = 352  ☒ 342 \u001b[0m\n",
      "\u001b[91m109-93  = 16   ☒ 14  \u001b[0m\n",
      "\u001b[92m415-648 = -233 ☑ -233\u001b[0m\n",
      "\u001b[92m858-586 = 272  ☑ 272 \u001b[0m\n",
      "\u001b[91m236-392 = -156 ☒ -155\u001b[0m\n",
      "\u001b[91m622-470 = 152  ☒ 142 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sub_model = Sequential()\n",
    "sub_model.add(LSTM(HIDDEN_SIZE, input_shape=(MAXLEN, ALPHABET_LENGTH))) # Encoder\n",
    "sub_model.add(RepeatVector(DIGITS + 1))\n",
    "sub_model.add(LSTM(HIDDEN_SIZE, return_sequences=True)) # Decoder\n",
    "sub_model.add(TimeDistributed(Dense(ALPHABET_LENGTH, activation='softmax')))\n",
    "sub_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "plus_model = Sequential.from_config(model.get_config())\n",
    "plus_model.set_weights(model.get_weights())\n",
    "plus_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "pre_loss, pre_acc, pre_val_loss, pre_val_acc = train(plus_model, X_train_sub, y_train_sub, X_val_sub, y_val_sub, encoder_sub, EPOCHS)\n",
    "new_loss, new_acc, new_val_loss, new_val_acc = train(sub_model, X_train_sub, y_train_sub, X_val_sub, y_val_sub, encoder_sub, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T18:56:46.432717Z",
     "start_time": "2019-05-28T18:56:46.202400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4VNXWx/Hvnkx6L4SEFEJvAQKE3qWDIAooiijqFXtBr9ervir2XrBiw3ZRUaSJ9Bp6i5TQCQmQXkivk5n9/hGMlAAB0iZZn+fJkzJnzlmD8Zc9++yzjtJaI4QQom4x1HQBQgghKp+EuxBC1EES7kIIUQdJuAshRB0k4S6EEHWQhLsQQtRBEu5CCFEHSbgLIUQdJOEuhBB1kLGmDuzj46NDQkJq6vBCCGGVdu3alaa1bnC57Wos3ENCQti5c2dNHV4IIaySUupERbaTaRkhhKiDJNyFEKIOknAXQog6qMbm3IUQl2YymYiLi6OwsLCmSxE1wMHBgcDAQGxtba/q+RLuQtRScXFxuLq6EhISglKqpssR1UhrTXp6OnFxcTRp0uSq9iHTMkLUUoWFhXh7e0uw10NKKby9va/pXZuEuxC1mAR7/XWt/+2tLtwPJ+XwzvJDZOQV13QpQghRa1lduMek5fHp2mjiMwtquhQh6jwXF5eaLqFcmZmZfPbZZ1f13JEjR5KZmVkpddTWfx+wwnD3drED4LSM3IWo00pKSi762KXC3Ww2X3K/S5YswcPD45pqswZWF+6eThLuQlQ3rTVPPfUUoaGhtG/fnjlz5gCQmJhIv379CAsLIzQ0lA0bNmA2m5kyZUrZth988MEF+5syZQr3338/ffv2pWXLlixevBiA7777jgkTJjB69GiGDh0KwDvvvEPXrl3p0KEDL774IgD//e9/iY6OJiwsjKeeeop169YxcOBAbrvtNtq3bw/A2LFj6dKlC+3atePLL78sO3ZISAhpaWnExsbSpk0b7r33Xtq1a8fQoUMpKCidEYiOjmb48OF06dKFvn37cujQIQBiYmLo2bMnXbt25fnnn6+if+3KYXVLIb2dS8M9XcJd1CMv/bGfAwnZlbrPto3ceHF0uwptO2/ePHbv3s2ePXtIS0uja9eu9OvXj59++olhw4bx3HPPYTabyc/PZ/fu3cTHxxMVFQVw0SmQ2NhY1q9fT3R0NAMHDuTYsWMAbNmyhb179+Ll5cWKFSs4evQo27dvR2vNmDFjiIiI4M033yQqKordu3cDsG7dOrZv305UVFTZ0sFZs2bh5eVFQUEBXbt2Zdy4cXh7e59Tw9GjR/n555/56quvuPnmm/n999+5/fbbmTp1KjNnzqRFixZs27aNBx98kDVr1vDYY4/xwAMPcMcdd/Dpp59e1b97dbG6cHd3tMXGoOSEqhDVaOPGjdx6663Y2NjQsGFD+vfvz44dO+jatSt33303JpOJsWPHEhYWRtOmTTl+/DiPPPIIo0aNKhuBn+/mm2/GYDDQokULmjZtWjY6HjJkCF5eXgCsWLGCFStW0KlTJwByc3M5evQowcHBF+yvW7du56wJ/+ijj5g/fz4Ap06d4ujRoxeEe5MmTQgLCwOgS5cuxMbGkpuby+bNm5kwYULZdkVFRQBs2rSJ33//HYDJkyfz9NNPX/k/ZjWxunA3GBSeTrYychf1SkVH2FVFa13uz/v160dERAR//vknkydP5qmnnuKOO+5gz549LF++nE8//ZRff/2VWbNmXfDc85f6/f29s7PzOcd95plnuO+++87ZNjY29oL9nf28devWsWrVKrZs2YKTkxMDBgwod824vb192dc2NjYUFBRgsVjw8PAoe1dwubprK6ubcwfwcrbjdF5RTZchRL3Rr18/5syZg9lsJjU1lYiICLp168aJEyfw9fXl3nvv5Z577iEyMpK0tDQsFgvjxo3jlVdeITIystx9/vbbb1gsFqKjozl+/DitWrW6YJthw4Yxa9YscnNzAYiPjyclJQVXV1dycnIuWm9WVhaenp44OTlx6NAhtm7dWuHX6ubmRpMmTfjtt9+A0j8we/bsAaB379788ssvAMyePbvC+6wJVjdyh9KTqnJCVYjqc+ONN7JlyxY6duyIUoq3334bPz8/vv/+e9555x1sbW1xcXHhhx9+ID4+nrvuuguLxQLAG2+8Ue4+W7VqRf/+/UlOTmbmzJk4ODhcsM3QoUM5ePAgPXv2BEqXHv7vf/+jWbNm9O7dm9DQUEaMGMGoUaPOed7w4cOZOXMmHTp0oFWrVvTo0eOKXu/s2bN54IEHePXVVzGZTEycOJGOHTsyY8YMbrvtNmbMmMG4ceOuaJ/VTV3s7VbZBko5ABGAPaV/DOZqrV88bxt74AegC5AO3KK1jr3UfsPDw/XV3qzjwdm7OJSUw5onB1zV84WwBgcPHqRNmzY1XUaVmDJlCtdffz3jx4+v6VJqtfJ+B5RSu7TW4Zd7bkWmZYqA67TWHYEwYLhS6vw/g/cAGVrr5sAHwFsVqvwqeTnbyQlVIYS4hMtOy+jSoX3umW9tz3ycP9y/AZh+5uu5wCdKKaUv97bgKnk525NZYMJs0dgYrOPkhhDiH999911Nl1DnVeiEqlLKRim1G0gBVmqtt523SQBwCkBrXQJkAd5UEW9nO7SGjHwZvQshRHkqFO5aa7PWOgwIBLoppULP26S84fMFo3al1FSl1E6l1M7U1NQrr/YMT2e5SlUIIS7lipZCaq0zgXXA8PMeigOCAJRSRsAdOF3O87/UWodrrcMbNGhwVQXDWVep5kq4CyFEeS4b7kqpBkopjzNfOwKDgUPnbbYIuPPM1+OBNVU13w6lJ1RBpmWEEOJiKjJy9wfWKqX2AjsonXNfrJR6WSk15sw23wDeSqljwBPAf6um3FLSX0aI2uliLXBra2vcutw6uCKrZfYCncr5+QtnfV0ITDh/m6pSNucu0zJCiMsoKSnBaCw/6v4O9wcffPCCx8xmMzY2Nhfd75IlSyqtxqpgle0HbG0MuDkYpQWBEFXo6aefPmdUO336dN577z1yc3MZNGgQnTt3pn379ixcuLDC+5TWwdXXOtgq2w9A6by7TMuIemPpfyFpX+Xu0689jHjzog9PnDiRxx9/vGxU++uvv7Js2TIcHByYP38+bm5upKWl0aNHD8aMGVOhhlrSOrj6WgdbdbjLCVUhqk6nTp1ISUkhISGB1NRUPD09CQ4OxmQy8eyzzxIREYHBYCA+Pp7k5GT8/Pwuu09pHVx9rYOtONzticvIr+kyhKgelxhhV6Xx48czd+5ckpKSmDhxIlDaVCs1NZVdu3Zha2tLSEhIue10yyOtgy9ed2Wzyjl3KF0xIxcxCVG1Jk6cyC+//MLcuXPLmnxlZWXh6+uLra0ta9eu5cSJExXen7QOrr7WwdY7cncpnZbRWltN83whrE27du3IyckhICAAf39/ACZNmsTo0aMJDw8nLCyM1q1bV3h/0jq4+loHX7blb1W5lpa/AF9FHOe1JQfZ8+JQ3B1tK7EyIWqHutzyt7LU9dbBVd3yt1Yqu0pVpmaEEOICVj0tA6VXqYb4OF9mayFEXSStgy/Oakfu3tIZUgghLspqw92rLNzlKlUhhDif1Ya7t3PpulK5SlUIIS5kteHuaGeDg61BmocJIUQ5rDbcoXT0flpaEAhRZWpTq94PP/yQ/Pwrvyr9hRdeYNWqVZVSw4ABA7iWJdzVyarD3UuuUhWi3rhUuJvN5os+7+WXX2bw4MFVVVatJeEuhLisqmjVO3fu3LLv/36HsG7dOgYMGMD48eNp3bo1kyZNQmvNRx99REJCAgMHDmTgwIFlz3nhhRfo3r07W7Zs4eWXX6Zr166EhoYyderUsj42Zx8rJCSEF198saxd8d9NxvLy8rj77rvp2rUrnTp1KmtjXFBQwMSJE+nQoQO33HJLWStfa2C169yhdDnksZTcmi5DiCr31va3OHT6/LtbXpvWXq15ulvFuhFWRavei/nrr7/Yv38/jRo1onfv3mzatIlHH32U999/n7Vr1+Lj4wOUBnJoaCgvv/wyAG3btuWFF0rvITR58mQWL17M6NGjL9i/j48PkZGRfPbZZ7z77rt8/fXXvPbaa1x33XXMmjWLzMxMunXrxuDBg/niiy9wcnJi79697N27l86dO1/Ra6lJVj1y95SRuxDV4lKter/99lumT5/Ovn37cHV1PadV77Jly3Bzc7uiY3Xr1o3AwEAMBgNhYWHldm6E0u6LZ/dlWbt2Ld27d6d9+/asWbOG/fv3l/u8m266CfinNS+UtgR+8803CQsLK+v8ePLkSSIiIrj99tsB6NChAx06dLii11KTrHrk7uVsR4HJTEGxGUe7i98OSwhrV9ERdlWp7Fa9RqOxrCGY1pri4n8Gaee3zy0pKSn32A4ODmW3wSssLOTBBx9k586dBAUFMX369Iu2If57/2fvW2vN77//Xm5HSWttTGjVI/eyq1RlxYwQVaqyW/WGhISwa9cuABYuXIjJZLpsDZdqz/t3kPv4+JCbm3vOfH5FDBs2jI8//rjsj9hff/1V9rr/bskbFRXF3r17r2i/NcnqR+5QeqPsAA/HGq5GiLqrslv13nvvvdxwww1069aNQYMGnXODjIuZOnUqI0aMwN/fn7Vr157zmIeHB/feey/t27cnJCSErl27XtHre/7553n88cfp0KEDWmtCQkJYvHgxDzzwAHfddRcdOnQgLCyMbt26XdF+a5LVtvwF2HXiNOM+38J3d3VlQCvfSqpMiNpBWv6KetnyF0pvtQfSPEwIIc5n3eHuJJ0hhRCiPFYd7m6ORowGJeEuhBDnuWy4K6WClFJrlVIHlVL7lVKPlbPNAKVUllJq95mPF6qm3AuOK2vdhRCiHBVZLVMCPKm1jlRKuQK7lFIrtdYHzttug9b6+sov8dK8ne2k7a8QQpznsiN3rXWi1jryzNc5wEEgoKoLqyjpLyOEEBe6ojl3pVQI0AnYVs7DPZVSe5RSS5VS7S7y/KlKqZ1KqZ2pqalXXGx5PJ3t5CbZQtQSF2sRLK2Dz1UdrYMrHO5KKRfgd+BxrXX2eQ9HAo211h2Bj4EF5e1Da/2l1jpcax3eoEGDq635HDItI4S4EvWldXCFwl0pZUtpsM/WWs87/3GtdbbWOvfM10sAW6WUT6VWehFeznZkFZgwmS3VcTgh6o2nn36azz77rOz76dOn895775Gbm8ugQYPK2ub+3R63IqR1cPW1Dr7sCVVV2jXnG+Cg1vr9i2zjByRrrbVSqhulfzTSK7XSi/i7v0xGfjG+rg7VcUghql3S669TdLByW/7at2mN37PPXvTxiRMn8vjjj/Pggw8C8Ouvv7Js2TIcHByYP38+bm5upKWl0aNHD8aMGVOhBlvSOrj6WgdXZOTeG5gMXHfWUseRSqn7lVL3n9lmPBCllNoDfARM1NXU10CuUhWianTq1ImUlBQSEhLYs2cPnp6eBAcHo7Xm2WefpUOHDgwePJj4+HiSk5MrtE9pHVx9rYMvO3LXWm8ELvknWWv9CfBJZRV1Jc5uHiZEXXWpEXZVGj9+PHPnziUpKYmJEycCMHv2bFJTU9m1axe2traEhIRctL3u+aR1cPWx6itU4axwl7a/QlS6iRMn8ssvvzB37lzGjx8PQFZWFr6+vtja2rJ27VpOnDhR4f1J6+Dqax1s1S1/4axwl2kZISpdu3btyMnJISAgAH9/fwAmTZrE6NGjCQ8PJywsjNatW1d4f9I6uPpaB1t1y1+AErOF5s8t5bFBLZg2pGUlVCZE7SAtf0W9bfkLYLQx4OFkKyN3IYQ4i9WHO0gLAiGEOJ/VhXuRuYiN8RvPOevu5SThLuqmmpo2FTXvWv/bW124Lzm+hAdWPcCB0/80pZSRu6iLHBwcSE9Pl4Cvh7TWpKen4+Bw9RdmWt1qmYFBA7FRNqw6sYp23qX9ybxd7Ig8eWVXrwlR2wUGBhIXF0dlNdkT1sXBwYHAwMCrfr7VhbuHgwfhfuGsOrGKRzs9ilIKL2c7MvKLsVg0BkP1XiggRFWxtbWlSZMmNV2GsFJWNy0DMDh4MLHZsURnRgOlLQjMFk124eUvYBBCiPrAKsN9UPAgFIpVJ0t7K3vLhUxCCHEOqwz3Bk4NCPMNY9WJ0nD3lHAXQohzWGW4Q+no/XDGYU5lnyobuctNO4QQopTVhvvgxqV3RFl1cpX0lxFCiPNYXbjnbdtO7G2T8NNutPFqw6oTEu5CCHE+qwt3g6MDBZGRZC9bxpDGQ9ibtpfM4lSc7Wwk3IUQ4gyrC3eH9u2xa9qUrPkLyqZmVp9cjadcpSqEEGWsLtyVUrjfMJqCyEgCMg00c2/GqhOr8Ha2kxOqQghxhtWFOwcX4x7/FhgMZC4oHb1HpkTi6lzI6byimq5OCCFqBesLd79QbG2ycG7pQ9bChQwOGoRFWzDZR8l9VIUQ4gzrC3fPEGg/AXefGEoSEgk8mkmgSyCn2Sn3URVCiDOsL9wB+jyOq18WBkdbshcsYEjjIaSYoig055FfXP4dzoUQoj6xznD3bYMh9HrcgvLJXr6CQQ16YcGM0eUg6TI1I4QQVhruAH2ewD04E11YSPDOeNxtfTC6RclySCGEoALhrpQKUkqtVUodVErtV0o9Vs42Sin1kVLqmFJqr1Kqc9WUe5bALjh27YWdmyZ73jy6+fbH6HyExOysKj+0EELUdhUZuZcAT2qt2wA9gIeUUm3P22YE0OLMx1Tg80qt8iJUv3/j3jiH/F2RDLPrgDKUsDR2aXUcWggharXLhrvWOlFrHXnm6xzgIBBw3mY3AD/oUlsBD6WUf6VXe76Qvrj3bAFA2F8ncbQ0ZU3yt8RkJFX5oYUQoja7ojl3pVQI0AnYdt5DAcCps76P48I/AJVPKWxHPY1zwyJy5s7hlZ7T0aqIh5Y9X+WHFkKI2qzC4a6UcgF+Bx7XWmef/3A5T7nglu1KqalKqZ1KqZ2VdtPfFsNw7+iJKTWTPplFtLQfx6nircze90fl7F8IIaxQhcJdKWVLabDP1lrPK2eTOCDorO8DgYTzN9Jaf6m1Dtdahzdo0OBq6r2QwYDr5CcwGC1k/fApn4ychi4M5L3IN8kozKicYwghhJWpyGoZBXwDHNRav3+RzRYBd5xZNdMDyNJaJ1ZinZdk6HwLrs2NZG/YhZ8Rxgc/QbHO46k1L1dXCUIIUatUZOTeG5gMXKeU2n3mY6RS6n6l1P1ntlkCHAeOAV8BD1ZNuRdhY8RjwkS0SZP09EM83b8v9jlD2Ja6ijUn1lZrKUIIURsorS+YGq8W4eHheufOnZW2P20qJPWu7qTvLMaxQyi773+GZ48+jbtLMcsn/IGbnVulHUsIIWqKUmqX1jr8cttZ7xWq51G2Dvi+9zMBfXIpPLCfdi89Qe+kYeSaMnl969s1XZ4QQlSrOhPuADRsi9v9LxMyKBlVkse0uT/Sc2sL/oxZyJqTa2q6OiGEqDZ1K9wBukzBoc9oQvodx7lNU6at28/tyx15cs00vt//PTU1DSWEENXJWNMFVDqlYPQMjPGRBHsf4XizsYyZv4BmGW68U/QO+9P2M73XdJxsnWq6UiGEqDJ1b+QO4OAO479F5SfRrONJYqc8RqvYXN77nzN/RS5l0pJJnMw+WdNVCiFElamb4Q4Q2AUGT4dDixl+nQ1LpzyHMauE9/5ni/f+BCYunkhEXERNVymEEFWi7oY7QI+HoMVQ1PLnePS2tnw8/lmSje48MTuPsVGOPLz6YT7d/SklFrl7kxCibqnb4W4wwNiZ4OSFw/y7ee1fvXlu0OMcDmjD6HkJvLQtmC//+pw7l94p0zRCiDqlboc7gLM3jPsGMmIJ2fQMr9zWjSc73cH+PtfTek00365sTlJKNOP/GM/cI3NlNY0Qok6o++EOENIbBj0P++cxLH8xUwe04N8+A4j/1zQc90bz2a8e9FUteWnLSzy69lHSC9JrumIhhLgm9SPcAXo9Bi2GwvJn+XdoHj2bevNQZhCWt2fA6Uzu+/g4L7vcyub4zdy06CbWnVpX0xULIcRVqz/hbjDAjV+Asy/G3+/i4xub4uFkywNRCu/vfsDGzY0203/hJ+N9+Dj68MiaR5i2dhqJudXW3FIIISpN/Ql3ACcvmPAdZMfjs3oan93WmcSsAp7ckknQzz/j2KkTlpc+4NPo3jwW9igb4zdyw8Ib+Hrf15jMppquXgghKqx+hTtAUFcY8gocWkyXxJ+ZPqYd64+kMmNHMsFff4X7uJvI+OIrhn+9l/ndvqBXo17MiJzBTYtuYkvClpquXgghKqT+hTtAjweg9fWw8gVu809iYtcgPl0bzfIjp/F/9VV8//MfctetJ2fcFJ5e58HM0FcwazNTV07liXVPEJkciUVbynZnKSykYN8+LMXFNfiihBDiH3Wmn/sVK8iEL/qB2UTRPau5eXYMx5JzWPhwb5r7umJKSiL9yy/J/G0uGnC7aSzL+7syM/E3CkoKaGvy5eb0ZrQ7XACRUejCQpzCwwn68gsMTtK3RghRNSraz73+hjtA0j74Zig0DCXxxt8Y/fkO3BxsWfBwb9wcbAEwJSSQ9sWXZM6bhwIcBw0g4+Be7E8kA5DsATFtvWjUJJTgnzfi1LUrQTM/x+DoWIMvTAhRV0m4V9T++fDbFOh0O9tCX2LSN9sZ0MqXLyd3wWBQZZuZ4uNJm/kF2cuW4dCuHS79+2Pq3p7VHGRJzFL2pu2l/37FA3+YMHduS9uvf8ToKCN4IUTlknC/EmtehYh3YMTbfFcylOl/HGDa4JY8NrhFhXcRmxXL3CNzSf59DlMW5HK0hSNZLz3ImLbj8HTwrMLihRD1iYT7lbBYYM4kOLIcffs8ntzlwfy/4pl1Z1cGtva9ol0VmYvY+tXr+H74K381VXw4wZ4+TQYyOHgw/QL74WLnUkUvQghRH0i4X6nCbPhmCOQmU3TXam78OYG4jHz+eKQPjb2dr3h3Gb/9RtLzL5DUMZDXbzCRZErHzmBHr0a9GNx4MAOCBuBu714FL0QIUZdJuF+N08fhy4Hg6k/cuEWM+mI3jTwcmfdALxztbK54dxm/zCFp+nRsmzQhf2h31rS18GfOZpLykjAqI90bdWdEyAgGBQ+SEb0QokIk3K9W9Fr4303QcgTrwt7jrh8iGRsWwPs3d0Qpdfnnnyd7xQpOf/c9BZGRYDDg3Ls32YO7sCo4i2UJa4jPjcfOYEe/wH4MbzKc/oH9cTA6VMELE0LUBRLu12Lr57Dsv9D9AT6yvZv3Vx3lpTHtuLNXyFXvsigmhqyFC8lasJCSpCQMbm64jRxJ6uCOLLE7xPLY5aQVpOFkdKJ/YH86+naknXc7Wnu1lrAXQpSRcL8WWsOyZ2Db51iGvMLUYz1ZdziVX6b2IDzE69p2bTaTv20bmfMXkLNiBbqoCPu2bXAfN45j3fxZmhpBRFwEqQWpABiVkeaezWnn3Y4ODTowMGigrL4Roh6rtHBXSs0CrgdStNah5Tw+AFgIxJz50Tyt9cuXO3CtDncoXUEzdwocWEj+6C8ZucaX/GIzix/tg69r5YykzdnZZC1eTOZvcyk6eBBlb4/rsKF43HgjOa0C2J97lP1p+4lKiyIqPYqc4hyMBiMDgwYytvlYejXqhdFgrJRahBDWoTLDvR+QC/xwiXD/t9b6+ispsNaHO4CpEH68EeJ3cnLk/xi2QBMa4Mb//tUde+OVn2C9lIL9+8mcO5fsPxZjyc1F2driEBqKY+dOOHXpgmNYJ6JJYWH0QhZHLyajKANfR1/GNB/D2OZjaezWuFLrEULUTpU6LaOUCgEW17twB8g/DbOGQ04Sa3r/wN1L8ujWxIsvJ3fBw8mu0g9nKSggb8sWCiIjyd8VSUFUFJhK2w3bNWuGS58+OPTvy46GuSyI/YMN8RuwaAudfDtxQ7MbGBYyTFbeCFGHVXe4/w7EAQmUBv3+i+xnKjAVIDg4uMuJEycue+xaIfMUfD0YDDYs7/kjjyxOIdDLke+mdCPYu2pbDFgKCymMiiI/8i/yt28nf9s2tMmEwc0Nlz59sPTuzBr/DH5PWUFMVgwONg4MajyIMc3G0N2vOzaGyn2HIYSoWdUZ7m6ARWudq5QaCczQWl/2un2rGbn/LWkfzBoBHkFEDvyRu387jo1SfHVnOJ2Dq+8EpyUvj9zNm8ldt47cdesxp6eDjQ32LVtS0DKQSJ8cFtod4IhbHr4ufvQO6E2wazBBrkEEu5V+dra98ouyhBC1Q7WFeznbxgLhWuu0S21ndeEOpWvgf54IbgGcHPE9kxekkZRVyIe3hDGivX+1l6MtFgr37SN3/XoKdu+mYF8UlpwcACxO9iQEOpJgX4DZVIzRTNmHozZi8XSl+IZBtB16M22822JQ9bO1vxDWpjpH7n5AstZaK6W6AXOBxvoyO7bKcAc4ua004IGssT9w12oDf53K5JkRrbm3b9OrutCpsmiLheLYExTs3UPh3n0U7NuHOTsLbbShxABFBgtFqoQCZcL5ZDoueWZifWFtL1cMg/vSvXEfuvl3w8/JT6ZzhKilKnO1zM/AAMAHSAZeBGwBtNYzlVIPAw8AJUAB8ITWevPlDmy14Q6QHg2zx0NWPMU3zGTavhD+3JfIv/o04blRbWo04CvKUlRE/O8/c/r777A7kUyWi4GlnWFlJ0W+s5EGTg1o6NSw9MO5IX5OfrTwbEFb77bSE0eIGiQXMVW1vPTSEXzcDixDXubltOv4bssJpvQK4cXRba0i4AG01uRt2szp778jb8NGtMFAnr87aY2cOdXQwDEvE3s9sol3KoQzrynYMYD2ri1p59Kclk4hNHdvhqu9GygDyqDAYAClMHp6ouwqf0WREPWZhHt1MBXA/PvgwEJ0+L94Xd/JV5tOcXuPYF4eE3rOzT6sQdGxY2T9+SdFh49QdPgwpvj4sseUkxMWLFBYhLJU7HfGxtMTz1tvxfO2WzH6+FRV2ULUKxLu1cVigVUvwOaP0S2G8b77f/l4YyITuwbx+o3trS7gz2bOyaHo6FGKDh+m6HgMyqBQDo4YHOxRDo4UGi0kmtKJz08kISeOhNwEsgoyUBpsLNA11oYOR0xYDIoZ/kCnAAAgAElEQVTD3RpybFgbaBqMp70njVwaEegaSCPnRjRwaiAndIWoIAn36rb9K1j6H3TDdnwZ8AZvbMpmfJdA3hrXARsrDvgrlVWUxcHTBzmQfoDE3ET0yXiarzxE261J2Jo0UU2NrOhgIdlDkeEKWU5ga7SnkUsjglyD6O7fnd6NetPMo5nVTG0JUZ0k3GvCkRUw9y6wd2N2s3d5bivc2CmAd8Z3wGhTv0emJRkZZM75ldOz/4c59Z9VstqgKHJ3ItvNSLKrmciG+RwIUhQ29aNXYB/6BvSlu3/3sqtuLdpCiaWEEksJZm3G2dZZRv2iXpFwrylJ+2D2zVCUzeKWr/Hwzgb0ae7DK2NDaeIjFw/p4mIKDx+mJCWFkpQUTMnJlKSkUpKSQvHJk5hOngSgyNHIwUDYF2ThYJAixcdIjq0Zfd5g3tPek65+Xenu350e/j0Icg2SEb+o0yTca1J2Avx0MyTvZ3ubZ7l7fweKSyzc178pDw5oflV3daovTMkp5O/YQf727eTt2I4pJrbsMbOdkWJPJ4o9XSnxdMHk5Uq8cxE7jXEcccwmxQO8PBvRza8bbbzb4GrnioutC652rjjbOuNq64qHgweudq5VVr8lLw9LQYGcQBZVRsK9phXlwty74ehyCtpN5I3im/lhXyEBHo68OLotQ9o2lBFmBZhSUiiI/AtTYmLpaD819Z/PyclY8vPP2T7f1Y4EdwuJbmZSPSDVXZHiDmluijR3MBkVDZ0a0tKzZemHe3OauzYlxL0xdg5X/85Km0xkzp1L6sefYMnLo8G0x/GaPBllI3/IReWScK8NLGZY8wps/hiMDpxqdx8PRvdkX0oxA1s1YPqYdld1823xD3NmJsWn4jDFnaL45Kkzn09SFBeHOSkJzJZzti9xtsdiNqNKzBjMGpuzfv3TfezJb+6PY2gojcL70Th8AEaXf0b5WUVZnMw+ycmck8TlxOHl6EXfRn1x3n6AlHffo/j4cZzCwzE4O5O7fj2OnTrh//pr2DdpUl3/HKIekHCvTdKjYeULcGgx2i2AdUEP8WhUUyxa8e6EjjXSl6Y+0CUlpfP68fEUx8djio/HfDoDZbQBoxFtYyDTnEuaKZPTOcno6Fi8YzPxzi79f8Ki4HRDR5L87DnmUUS0ZxFxPookTzDbKJomaiavMdPuJOQ38sTx0ftoPWYySimy//iDpNdeRxcW0uDxx/G6Q0bxonJIuNdGsRth+bOQuIdiv05ML7yNn5ICeGBAM/49tFW9WjJZW5ktZqKP7yJ2+2qy90Rie+QkDVOKcU8v/GcjGwPGRgGUnDpFsZsja4b48EOzREpswNfJlz4BfQhrEEZHQzC2731D7pq1OIaF4f/aq9g3a1ZzL07UCRLutZXFAnvnwOqXICeRw67d+XfaaDyad+OjiZ3wdJbL9WsjS34+RTExFB8/TtGxaIqPH8e+RXO87r4bGxcX0gvS2RC/gfWn1rMtaRs5xaXdOT3s3Jlwwp8Bc49hm1uIwdUV26BA7AICsQ0MxDYgALvgIBxCQzF6Xdv9eUX9IOFe2xXnw46vYOOHUHCalZau/Og4if/ccROhAdKYy5pZtIWYrBh2p+xmd+pudqfsJiMhhr77NQ0zISTPEb9sA67pBRiKS8qeZ9ekCY5dOuPUuQtOXTpjGxwsJ93FBSTcrUVhNmybiXnjRyhTLkssPbEd9CzD+vet6cpEJcoozGBv6l6i0qNKb3ieFkVWYQbueRCYYUOrBGh5ykyLU2ZczswAZTorEkNcsbRrjk+XnrTtPRpfn/LvlavNZkpSUzE4OGDj4VGNr0xUNwl3a1OQQf76GRi2fY7BYmKW3wvcNOl+fN0caroyUQW01sTlxrE/bT+HMw5jMpfeJxeLxiUhE68jyXgcTsTlSAKeaaVpb1GQ1NCOvJYBeHj545llxvF0PjoljZKUFDCbUQ4O+L34Ih43jq3BVyeqkoS7lSrJTibt6/H4ZEXxf+ohOo+6jwnhgfL2vB4rTE/h6KalJO/YgDnqEN4xp7E1aU67lq7fz/O0B18fHBsF0jwyBad9x/GYMJ6Gzz2HwUEGB3WNhLs1K8ql4IcJ2Mdv4VnTPZxqMoE3buxQ5TfjFtbBYrGQnJ9MdFY0xzKOcSyz9ON41nGKivO5eYOFmzZrMoO9ML8yjc6dR+JkK787dYWEu7UzFaDn3IE6toI39Z18bxnJk0NbclfvJrJkUpTLoi0czTjK1sStJK5YzKDvozBomHm9LSV9uzCy6UiGNh4qd9KychLudUFJMfx+DxxcxDyPu3giaQidgj14Z3wHmvtWXX8UUTfknooh9pGHsDkUw6ZeHvwamkO6jx0DggcyptkYegX0wtZgW9NlXrNF0Yt4f+f7LL5xcVn30LpMwr2uMJfAwgdh7xyONP8Xd0X3JdVkz7TBLbm3b5N630pYXJqluJiUt94mY/ZsAPIauLAjpIStjYtJaOXNoFYjGdt8LK29WtdwpVdv0pJJ7E3dyxt93+D6ptfXdDlVTsK9LrFY4M8nYNe3AKQbfdlT1IgMl+b06tkX/5ZdoGFo2T1OhThfcVw8eRsiyI3YQN7WLeiCQkqMBg4GweFGGlOzIDr2Hsug7rfi4WA9SynjcuIYMW8EAAODBvLRdR/VcEVVT8K9rtEaotdA4h50ygFyTuzBMfs4tpReBGNpMRzDhG/BTk6ciUuzFBeTv2MHeREbyN64AVNMTNl9cXMdIKexN14dwmkxfgrOHcNquNpL+3rf18yInMHAoIFsit9ExMQInG3rdjM+Cfd6ID0rl8/mrcDu2HKesp2DqWEn7O+YC87eNV2asCKWggKKjhwhZscaYneuQR+JITDFjF0JpPVoSYv/vohf6841XWa5blp0E85GZ6Z1mcady+7krb5vMbLpyJouq0pVNNxlwtaKebu78PxdN9HulheZxpPopH3kfjYQMmJrujRhRQyOjjh27Ejbf01j5Mw/GLRiJ/G/vMqmYQG47DpC2o2T+H3qMLZELcWiLZffYTU5mnGUoxlHGdl0JGG+Yfg6+rLixIqaLqvWkHCvA67v0IinHnuSV7zeoCQ3jexPBpIXK++KxNVxMDowMnQc/5qxCveFszk1qA2tNp7E4dYn+OjBXnyz9WPicuJqukyWxizFRtkwtPFQDMrA4MaD2Ri/kXxT/uWfXA9cNtyVUrOUUilKqaiLPK6UUh8ppY4ppfYqpWrn+7c6LtDTiZcevoeFXb4lp8SA+m4U0VsW1XRZwso1bdqZEZ/MI2TxQkp6dGTY2iw63/sZS6YMZfq7o/klajYZhRnVXpfWmqUxS+nu3x3HgydJePpphgQMpMhcRERcRLXXUxtVZOT+HTD8Eo+PAFqc+ZgKfH7tZYmrYbQxcOeYYaTesph45Ufwsims/346hQV5NV2asHIuTVvS9atfCJk7F9frR9Ej1p5bvj5Gk8mv8uPdfXn1i0n8cXRhtQX9vrR9xOXGMaLxMJJeeYWshYtocSgXH0cfmZo5o0InVJVSIcBirXVoOY99AazTWv985vvDwACtdeKl9iknVKtWVmY6CV/eQpv8HaQqLzLC7qfliEdkNY2oFLq4mJyNG4mf9wvmiM3YFJs57QLHGilym/vj1bk7ob1voF1IVwyq8md/39r+Fr8e/pWl3i+S/sTTYGODS//+/HBHIxYcW8D6W9bX2ZYLlbpa5jLhvhh4U2u98cz3q4GntdaXTG4J92qgNfs2LqJk3dt0MkeRbfDA3OMhPPvdDw5uNV2dqCPMuXlkr1pJwqrFFEZF4ZSUBYAFSPaxIa9FI1x696btiNtoGNDi2o9nMTN47mDCvDvyyIfH0SUluAwcyOnvvyfv1w+4a+cTvNP/HYaHXGrCwXpV52qZ8q6cKfcvhlJqqlJqp1JqZ2pqaiUcWlySUrTvewPtntnAgk7fsMccgufm1yh8tx2miA9KL44S4hrZuDjjOXYs7T75mi7rttJy6xY8P/uAzMnDKQlogN+eOPze/YW0QWNYPqQTC565ja2rfyS/+OqmC3ck7yCtII2b4vwoOnoUn4cfwmPCeDCbabwpBm8Hb1bGrqzkV2l9ZFqmHknMKuDH3xfQOeYLBtv8RULgSPzv/BZlK21hRdUxl5g4smUpp1YuxLhtLw1P5GIAspwgsWcz2kx5lNZdh1Z4fy9ufpEVx5fx42xvDEYbmixciDIYiL39dsxp6fz8Yi8WHf+D9besx9HoWHUvrIZU58h9EXDHmVUzPYCsywW7qBn+7o785+5bcbrjN752mEKjuCUcfGcQB6NP1HRpog6zMdrSpu8Yhr78Ddct30HjiNXkPvMvskODabYuGj35MVYP78b2b97CnH/pZYzF5mJWnljJ3QktMMXE4PPwIyhDaYx5jBtPcWwsI7JDKCgpYEPchup4ebVWRZZC/gxsAVoppeKUUvcope5XSt1/ZpMlwHHgGPAV8GCVVSsqRa8WDZjy1AdsDHub5sWHsPt+GG/9tIyUnMKaLk3UAy6+jeh655MM/WE5gauXEXPHAAy5Bbi+8x17e3Zl0xNTyI05Vu5zN8ZvJK8wm57LTmLfujWuQwaXPeY2bCgGZ2f81h7Ay8Gr3q+akfYD9VzukQhs5txGXoniYf5L/4HDubtPCPZGm5ouTdQjxSXFrP9zJmlzfqLtnizMRsXJh65n0JTncbX7p731U+ufwubPddy5KJfAzz7F9brrztlP4vMvkLV4MfPeG8WCxOV1cmpG2g+ICnFp2Q/HB9bi7u7B94aX+GvFj4z4cAMRR+SEt6g+dkY7htzwKBNnb6Hwp3fJ9HOh1ft/8M29fZmx7T3SCtLIN+WzIXYt4zdrHEJDcRk48IL9eIwfhy4oYFi0CwUlBWyK31QDr6Z2kHAX4NMC26lrsG8Uyhd2H/Jw4Rc8MGs9D87eRUJmQU1XJ+oRpRTdO45i4B8b0eNHMGxbEY2f/YaJs4bw8JqH6flXAc5peTR49JFy7yvs0KED9i2a47UyEk97T1bE1t+pGQl3UcqlAdy5GNX9fm4sWcoW9+coPrSSQe+t5/N10RSXyLJJUX2UnR1tX32fRu+9S6vT9rzznUZv3sWELQqHsDCc+/Yt/3lK4T5uHIV793KjMZx1cesoLKmf55Ik3MU/7JxgxJuou5fj5urG1zZv8I37N8xctpMRMyLYF5dV0xWKesZ91Ciazp2Lm28g/5lTjGeWGd/HHi131F72nDFjwNaW63ZbKCgp4Lv931VfwbWIhLu4UHB3uG8D9P03vfJWs93jWboXbGT8zM3Mi6z5boCifrFv1owmv87Bffw43MeOxalHj0tub/TywnXgQBxXb2dM8Eg+3/M5WxO3VlO1tYeslhGXlrgXFj4ESXtZ7TSCB05P5PbeLXl2ZGu5f6uotXIjIjg19T583n+be4u/IaMog99G/4avk29Nl3bNZLWMqBz+HeDetdBnGoPyl7LK+13+2BTJ5G+2k55bVNPVCVEu5969Mfr5UbDgD94f8D4FJQU8tf4pTBZTTZdWbSTcxeXZGGHwdBj/LcHF0UR4vITp5HbGfLKJqHiZhxe1j7Kxwf3GseRt3IT/qXxe7PkikSmRfBz5caUeR2tNoclcqfusLBLuouJCb4J7VuLo4Mivdq8womQV4z7fzHebYigxy2oaUbt43nILRh8fYm+7je6rE7i5+Xi+3f8ta0+urbRjrDiQTOdXVtbKd7ES7uLK+IXC1HUYGvfk/0o+5WOPn3n1j70Mn7GBdYdTaro6IcrY+vnRZOECXAcOJPW997n986P0VM15btNznMo5VSnH2Bl7mvxiM/tq4TtYCXdx5Zy84PZ50PNhhuYuJLLh67Qu3s+Ub3dw56ztHE3OqekKhQDA6OlJwIwP8X/jDYoPHmLajJP02FvEk2ufoMh87aPtYym5ABxMrH2/8xLu4urYGGHYa3Dzj7jpHD4pfIaVIbM5efI4w2ds4PkFUZzOK67pKoVAKYXHjWNpsnABjq1ac+/8fIZ9u597f5vIzqRrW7F39Ey4H0jMroxSK5WEu7g2bcfAwzug75O0SF3JGrsn+SRkE79uP07/t9fy8eqj5BWV1HSVQmAXGEjjH3+gwbRp9DyieOTtI3z77p38e92TJOQmXPH+8otLiD/TnuOghLuok+ycYdAL8OBWVONejEj4hL0NX2aabyTzVq1nwNtr+GFLrLQwEDVO2djgc99Ums6bh3eLdjy82ELPN5Yz9Zvr+XT3p+SbLt1P/mzHU/PQGpo1cOZ4am6tWzUj4S4qj3czmPQb3DoHe0zcnfoma+2fZL3lTlounci8N+9k5x9fYMmonJNZQlwth1ataPLzL/hNn0670468+VUR6R9/yo2/Xc/8o/MpNl9+SvHv+fYxHQOwaDhSy841yRWqomqYSyDlACTuRifsJidmBw7pB7HDhAkjiV2fJnjEv8Eg4wtRs0rS0kh+8y2yFy8m3ceOlW1LcLRzoqNvGO19O+Jo6wgo7Js3w6V//7LnvbP8EDPXH2fpY30Z+kEEb41rzy1dg6u83opeoWqs8kpE/WRjLL261b8DqvMduAEWUzFrN0VgiHiL/jte49CBFfhMnoWPX9X/DyHExRh9fAh49x3cbxyL3SuvMjEiFsgFNpLDRs4ej3vcOhG/Z55B2dlxNDmXEG8nmjdwwcnOptatmJFwF9XGYGvHwAGDye/ZnxVz3qFv9Afkf96blZ1eZeDoyVXeq8Zi0aTlFeHrKjcEFxdy6d0b56VLwGRCA0fSD/HTgdmsiF0OZguP7gug08+/UHDgAEEffcSx1Fxa+LpgMCha+bnWuhUz8p5YVDsne1uG3vEsabctJ8/OhyG7H+XPtyaz41jV3Vdda820X3fT5821HEupXSMsUXsopVB2dhjs7Gjt34GXB73FoltXMLHL3XzZp4D3xxrIOrCXfdcPwy1mOc0bOAPQxt+Ng4nZ1NQ0d3lkzl3UKG0q4MScpwk59j2HLYGsdrsR/563MDS8Dc72lffG8setJ3h+QRQGBb2b+/DD3d0u2RNciPOVWErYnridjZt+JvzDNfhmWPhtiCvud9yCQ8EA3v4ziY1PDyTQ06lK66jonLuEu6gVCg8uo/CPp/HIj6VY27CZjiQFX0+7gRMJbdLomoJ4b1wm4z/fQq/m3vRr0YCXFx9g5u1dGB7qV4mvQNQnCzdHcfqFafSIi2NrawNz+xo5ZhPO9H4Pc2vnTlV6bAl3YX20RifuJnnzTzgcmo9HSSr52p7tdt2xhN9D7+uux972ykbzmfnFjPpoIwCLH+mDq4ORUR9tJK+4hFVP9MfB1qYqXomo42asOsqMVYfYFBRH5uefQUkJBwMVq8MMeIwYwV2d76O5Z/MqObaEu7BuFgt5xzYQv+FH/OKW4aZz2KdaktDuPnqOmoybo30FdqG594edRBxN5bf7exEW5AHAluh0bv1qK9MGt+SxwS2q+pWIOujhnyLZE5fJhv9cR0l6OlkLFrDvi29pmJ1OngOsD1VkD+9Og3ZdcLVzxc3ODVc717KPhk4N8Xb0vqpjy1JIYd0MBpxb9qdly/7o4jyOrfyShpEzaR/1JDH73mNj0zvpMvoBGnq5X3QXMyOiWX0ohZfGtCsLdoCezbwZ1cGfz9YdY1yXgCqfIxV1z7GUXJo3cAHA6O2N9z33MMeuI+bInTyjDzB81WoMO7eS4LWVv5opljdTHAxSlBhLpxfvCr2LJ7o8UaU1SriLWk/ZOdN81DQY/ggnN/2McdMMRsa8QcqMz1nr3g/HoDCatOtOw+adSlshUDo6f3f5YSa0c+GOhjGwYR4kRILZBMNe57mRbVh9MJnXlxzks0ldavgVCmtitmiOp+XRr2WDc37eppE7HxwI4oPp/8I+P4fsP5fgvH4djbZtZ9SOYnCwp6RzW/LCW+Hh1K3K66xQuCulhgMzABvga631m+c9PgV4B4g/86NPtNZfV2KdQoCNkeB+k6Hv7aTsWU7Wmg/plr0S5/2LYD9YUGTYB1Ls05achFw2OEQTEJ0E0Wee79kECjLgi/40uuFjHhoQynsrj7DpWBq9m/vU6EsT1uPU6XyKSyw093U55+dt/N3QGg4l5dClsSdet0/C6/ZJWAoKyNu2jbyIDeSuX49x81945jhCmz5VWudlw10pZQN8CgwB4oAdSqlFWusD5206R2v9cBXUKMS5lMI3bDi+YcPRFjMnYg5zbO8WsmN345x5iJandtNOWXBr1hWadIVGncC/Y2kf+sxTMPcu+G0KD4Tfy3zPIUxftJ8lj/XFVm74LSrg7za/F4a7K1DaIbJLY8+ynxscHXEdMADXAQPQ+v8ojolB2V3+nNG1qsjIvRtwTGt9HEAp9QtwA3B+uAtR7ZTBhsbN2tK4WVsACk1mdp3IwM3BloDAcubjPYJgyhJY/RLGLZ8w33MLo5L+xY9bgrm7T5Nqrl5Yo2MXCfcAD0fcHIyXvFJVKYV906ZVWt/fKjJUCQDObuMXd+Zn5xunlNqrlJqrlAoqb0dKqalKqZ1KqZ2pqalXUa4Ql+Zga0Pv5j60Ly/Y/2a0K73RyC2zccs/yXKH59i78kcW7Y6vdW1bRe1zNCWHhm72uDnYnvNzpRStz1ypWhtUJNzLu3rk/PWTfwAhWusOwCrg+/J2pLX+UmsdrrUOb9CgQXmbCFF92lyPui8Co08zPlTv0W9+VyJfG0DE5w9zYuMcdOYpqEWXk4vaITollxa+ruU+1tbfjcNJOVgsNf97U5FpmTjg7JF4IHDObUu01ulnffsV8Na1lyZENfBqgv19q7Ds+YXCg5sIPrWLhkk/YZv8I6yCfDtvdKNOOIV0QwV2gUadS+fuRb2kteZYSi4TwsudnKCNvyv5xWZOnM6niY9zNVd3roqE+w6ghVKqCaWrYSYCt529gVLKX2v9d9enMcDBSq1SiKpktMfQ5U78utwJQFZ2Nps3r+dk1CZ8sqLocPwgzWJXo868YS1wbYxtcFeMjTqCbxto0Arcg0B61dR5iVmF5BWbL5hv/1sbfzeg9KRqrQ93rXWJUuphYDmlSyFnaa33K6VeBnZqrRcBjyqlxgAlwGlgShXWLESVcndzY8Tw0TB8NMdTc9kec5ofY06RF7sL3+z9dMyMJix7NX7755Y9p8TojNm7BXZ+bVC+bcC3bWnwuwVI6NchF1sp87eWDV0xqNJwH9nevzpLu0CF1rlrrZcAS8772Qtnff0M8EzlliZEzWvawIWmDVygWzDQm8z8Yv46mcnskxnEnjqFOfkQHnnHaVESR4uEOFomLcNX/Vz2fLOtK/i2xqZh2zMj/EBwCwS3RuDiCwbpbWNN/l4p0+Ii4e5ga0PTBi614qSqXKEqxBXwcLJjYGtfBrb2BVoBg8kpNHEkOZfDSTmsTMrmZEICluQDBJliaVESR6tTcbSJn4c75/aR1wYjytW/NPAbdYKgbhDUA9xqdsQnLu5YSg6eTrZ4u5xZpx69FiLegfGzwLW0y2gbfzciT2TUYJWlJNyFuEauDrZ0aex51oUroWg9hLiMAg4mZrMtMYdvEzJJTErAkhVPQ52GvzqNv0onOCuTZnlptDj1NbZbPwOgxDUQm8Y9UEHdwMkbtAUs5tLP2gLaDB6NoXHv0mWdotocO3ulTHE+LHoUsk7Ckqfglh+B0pOqf+xJICvfhLuT7SX2VrUk3IWoAkopgrycCPJyYmi7f/rGm8wWTp3OJzY9j+OpeWxLz+Pn1DxikjNokHeUcMMROmceoWv2ahpGzb3EEQB7N2g+GFqPKv3s6HHp7cU10VpzNCX3n7n0jR+UBnubMXBwERxYBG3H/HNSNSmbHk2vrvNjZZBwF6Ia2doYyubxr2t97mOZ+YM4lpLLkeRcZiZnk54YS+rpDJJzijBpAxoDFq1wsLNhgHsSw2z+ov3R9Tjtn1c6xdO4FwSEg6kAinNLP4rOfDYXg3OD0qkDF7/Sz65+4OpfevJX3gFcVnpeMZn5ptJukOnRsOlDaD8Bxn4OXw2EJf+GJn1pe9aKGQl3IQQeTnaEh3gRHvL3OvpQAIpLLMRl5HPidD4n0vKITc/nSEouCxM7cjpvImEqmiE2uxgRG0njmI0UGxwpMTqh7VwwOLhidHTFzt4dlR2Pjt8FeWllyzoBsHWC4B7QpD806Vfah+f8E70lxZCTAFlxpdv7dQCb+hUfR5P/PpnqDEsfBBt7GPIK2NjCmE/gq+tgxf/hO+YTvJztavykav36ryOEFbIz/jPap9U/P9dak5pTxIHE7hxMHM0HidlEp+QQn1VIZrbpovszUoIPWfiqTAJUGoOMx+h58v/bu/cYuao6gOPf38w+ZrqP7nanu32tbG1pKU2hIBJoMakEtSIWFEswmmAwIVHDKyIBE0M0QeM/SiJoYgTLH4ASlIdoghUQFAxCC0hLeWxLS8u+2877cXdmfv5xbum2XcrS7uwwd36fZHLuPXNn5vwyd373zrmPs52FO58CoNw8G+lbizQ0u2Se2AepIY64ML2pzW0Q+i6Avs+4DULAk33/qEvuK9PPQf9m+MJPDx/8XrAa1lwLz92BrNrIivlt7Bis7kDswf42jAkwEaG7PUJ3e4R1y7uPeC5dKDIQz/HewRz74jlGUwX3GiAkggiEBMZLytOjae4aSJJOvcf5oddZU9zGmje30hAOk4nMo9j2aUILe2mZ20fn/MW0lFOw+9/u8Y/b3Ac2tbqzfRac7c78WXi26/IJ0Dn+/cMpYs0lOp/5EcxdAedec+QC626BHX+Bx67jjMW/5+4XD1IslWmo0t1GLbkbE0CtzQ0s62ljWc/k90CZTLpQ5I3BJNsHktw5kOAdvwtodHdhwlIebc0tzG3fwNzWjSxZkuXs8nZOK/yPRaOvMnvXM4j6N19r7XGJft4qd/C3MeoeDRHXtdMYheY291yk/fAyH9MNQv9omh+0/A1J7IVv/dV1x0zUGIUNv4JNF/PVxCZ+U/WmEYUAAAbsSURBVFzPrrHMR/oOppMld2MM4DYIR/b5O5lCkXcPZNmzP8ue/RkGE3lGUwVGUnmeHwrxaGoZGW8J8BUiFDhd9rAq9A7npHdzZv92Fr31BKFj7jX4AUKNLtFHO90B4FldrmyJubJ9AcSWuYFXZvggcG7obS4vPQSrrnDdUZPpWwvnXM3SLZs4K7SU6x5o444rV3PavPYZbSvYANnGmGmQKRQZTuYZSuYZjLtyIJ5jKJFnKJ7hYCJBIZchKh7NeETwaJECsSaPWEOBroY8neEcnaEc7ZKjU9J0kqCtlGDW+AEavTii5cMfKGGYsxhiyyF2qrtPP7jrAcoldy1A2f8HEe10G4dZMb/sgsjsj/QPIZH12Pqzi1jb1E/TDVvfv2BpUvkk/Po80jKLjemb2Jmfzc3rl3P12sWEQif/r2SqA2RbcjfGzIisV2Qg7pL+YCLHQDxPMj9OOl8k4xVJ5YukC0XS+SIHMh77M977rw1RpoM0vaExzoyOsLJpmKUyQG95L12FfYS1+NEaE2p01wVEOo4tG44dJWlsbITY2w/y1upbWXbZLR/+/m89AfdfAcBow3yeLSzhYNenuHTD5cxdfMZJdT1ZcjfG1LTxUpmxdIHhZIGRZJ6RlCuHknmGkgWGE246ncszhyRKiBJCiRBlQpT84So6yDCvIUVvc5ZFTRl6GtJ0h9PMCWXokAxtmmFWOUWkmKJxPIGUxxF/GItDKXi8XOY/3lJOufZxTume4sViw9th1zPou89T2PkcEe8AAF5TB03rbnJn15yAqSZ363M3xnwsNYZDzJ8dZf7s6HGXy3klxtIFcuMlMoUiOa9E1iuR8YpkvRLx7DjxnEciO87OrMeW7Djx7Dj7kwUOZDyON65GtDFMS3OYQqmMp2Vejx1nhK+j9ayEnpXI+d8losrendt4+JGHmBd/meg78OU1U3+rE2HJ3RhT06JNYXrnzDqh15bKysGsx1i6wP60K5O5cX/jUCLnbyCyXomVC9oJn2ifuQi9S1fxnRtXcudT/axbXvmR6Cy5G2PqVjgkxFqbibUe289eCY3hEDd+btmMfFZ1zq43xhhTUZbcjTEmgCy5G2NMAFlyN8aYALLkbowxAWTJ3RhjAsiSuzHGBJAld2OMCaCq3VtGREaBPSf48hgwNo3NqSX1GrvFXV8s7g92iqp+6CWuVUvuJ0NEXprKjXOCqF5jt7jri8V98qxbxhhjAsiSuzHGBFCtJvffVrsBVVSvsVvc9cXiPkk12edujDHm+Gp1z90YY8xx1FxyF5H1IvKmiPSLyBQGM6xNInKPiIyIyLYJdXNEZLOIvO2XndVsYyWISK+IPC0iO0Rku4hc79cHOnYRiYjIf0XkVT/uH/v1i0XkBT/uP4pIU7XbWgkiEhaRl0XkcX8+8HGLyG4ReU1EXhGRl/y6aVvPayq5i0gYuAv4InA68HUROb26raqYTcD6o+puAZ5U1VOBJ/35oCkC31fVFcB5wPf87zjosReAC1X1TGA1sF5EzgN+DvzSj/sg8O0qtrGSrgd2TJivl7g/q6qrJ5z+OG3reU0ld+BcoF9Vd6mqB/wBuLTKbaoIVX0WOHBU9aXAvf70vcBlM9qoGaCqg6q61Z9O4X7wCwl47Oqk/dlG/6HAhcBDfn3g4gYQkUXAl4Df+fNCHcT9AaZtPa+15L4Q2Dthfp9fVy96VHUQXBIEuqvcnooSkT7gLOAF6iB2v2viFWAE2AzsBOKqWvQXCer6fgdwM1D257uoj7gV+LuIbBGRa/y6aVvPa20M1clGp7XTfQJIRFqBPwE3qGrS7cwFm6qWgNUi0gE8DKyYbLGZbVVlicglwIiqbhGRdYeqJ1k0UHH71qrqgIh0A5tF5I3pfPNa23PfB/ROmF8EDFSpLdUwLCLzAfxypMrtqQgRacQl9vtU9c9+dV3EDqCqceCfuGMOHSJyaCcsiOv7WmCDiOzGdbNeiNuTD3rcqOqAX47gNubnMo3rea0l9xeBU/0j6U3AlcBjVW7TTHoMuMqfvgp4tIptqQi/v/VuYIeq/mLCU4GOXUTm+nvsiEgUuAh3vOFp4Gv+YoGLW1VvVdVFqtqH+z0/parfIOBxi0iLiLQdmgY+D2xjGtfzmruISUQuxm3Zw8A9qnp7lZtUESLyALAOd5e4YeA24BHgQeATwLvARlU9+qBrTRORC4B/Aa9xuA/2h7h+98DGLiJn4A6ghXE7XQ+q6k9E5JO4Pdo5wMvAN1W1UL2WVo7fLXOTql4S9Lj9+B72ZxuA+1X1dhHpYprW85pL7sYYYz5crXXLGGOMmQJL7sYYE0CW3I0xJoAsuRtjTABZcjfGmACy5G6MMQFkyd0YYwLIkrsxxgTQ/wGBnTsqgqGe3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f004811cda0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pre_loss, label='loss pretrained')\n",
    "plt.plot(pre_val_loss, label='val loss pretrained')\n",
    "plt.plot(new_loss, label='loss untrained')\n",
    "plt.plot(new_val_loss, label='val loss untrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Ändere die zuvor verwendete Netzarchitektur so ab, dass anstelle von `LSTM`s `SimpleRNN`s oder `GRU`s verwendet werden, trainiere diese und vergleiche erneut den Lernerfolg. Was fällt auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T19:04:15.986721Z",
     "start_time": "2019-05-28T18:56:46.434553Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 1.8812 - acc: 0.3197 - val_loss: 1.7457 - val_acc: 0.3524\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 1.6964 - acc: 0.3757 - val_loss: 1.6499 - val_acc: 0.3991\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 1.6077 - acc: 0.4155 - val_loss: 1.5558 - val_acc: 0.4275\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 1.5094 - acc: 0.4573 - val_loss: 1.4601 - val_acc: 0.4727\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 1.4021 - acc: 0.5014 - val_loss: 1.3391 - val_acc: 0.5198\n",
      "\u001b[91m256+811 = 1067 ☒ 1077\u001b[0m\n",
      "\u001b[91m408+70  = 478  ☒ 590 \u001b[0m\n",
      "\u001b[91m564+84  = 648  ☒ 720 \u001b[0m\n",
      "\u001b[91m974+806 = 1780 ☒ 1708\u001b[0m\n",
      "\u001b[91m308+661 = 969  ☒ 100 \u001b[0m\n",
      "\u001b[91m391+809 = 1200 ☒ 1282\u001b[0m\n",
      "\u001b[91m509+203 = 712  ☒ 641 \u001b[0m\n",
      "\u001b[91m958+678 = 1636 ☒ 1525\u001b[0m\n",
      "\u001b[91m506+526 = 1032 ☒ 1031\u001b[0m\n",
      "\u001b[91m916+554 = 1470 ☒ 1488\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 1.2495 - acc: 0.5596 - val_loss: 1.1608 - val_acc: 0.5878\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 1.0525 - acc: 0.6344 - val_loss: 0.9571 - val_acc: 0.6736\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.8834 - acc: 0.7069 - val_loss: 0.8312 - val_acc: 0.7256\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.7580 - acc: 0.7644 - val_loss: 0.7087 - val_acc: 0.7881\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.6647 - acc: 0.8023 - val_loss: 0.6238 - val_acc: 0.8188\n",
      "\u001b[91m297+998 = 1295 ☒ 1285\u001b[0m\n",
      "\u001b[91m487+315 = 802  ☒ 792 \u001b[0m\n",
      "\u001b[91m279+713 = 992  ☒ 190 \u001b[0m\n",
      "\u001b[92m688+589 = 1277 ☑ 1277\u001b[0m\n",
      "\u001b[91m755+992 = 1747 ☒ 1647\u001b[0m\n",
      "\u001b[92m360+935 = 1295 ☑ 1295\u001b[0m\n",
      "\u001b[92m988+490 = 1478 ☑ 1478\u001b[0m\n",
      "\u001b[92m716+572 = 1288 ☑ 1288\u001b[0m\n",
      "\u001b[91m104+854 = 958  ☒ 967 \u001b[0m\n",
      "\u001b[91m6+912   = 918  ☒ 183 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.5754 - acc: 0.8402 - val_loss: 0.5604 - val_acc: 0.8414\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.5187 - acc: 0.8561 - val_loss: 0.5075 - val_acc: 0.8515\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.4613 - acc: 0.8764 - val_loss: 0.4636 - val_acc: 0.8678\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.4149 - acc: 0.8902 - val_loss: 0.4068 - val_acc: 0.8903\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.3790 - acc: 0.8993 - val_loss: 0.3710 - val_acc: 0.9005\n",
      "\u001b[92m328+538 = 866  ☑ 866 \u001b[0m\n",
      "\u001b[92m61+713  = 774  ☑ 774 \u001b[0m\n",
      "\u001b[91m191+329 = 520  ☒ 510 \u001b[0m\n",
      "\u001b[92m108+790 = 898  ☑ 898 \u001b[0m\n",
      "\u001b[91m422+496 = 918  ☒ 928 \u001b[0m\n",
      "\u001b[92m497+489 = 986  ☑ 986 \u001b[0m\n",
      "\u001b[92m296+212 = 508  ☑ 508 \u001b[0m\n",
      "\u001b[91m252+855 = 1107 ☒ 1106\u001b[0m\n",
      "\u001b[91m989+2   = 991  ☒ 193 \u001b[0m\n",
      "\u001b[92m175+775 = 950  ☑ 950 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.3447 - acc: 0.9096 - val_loss: 0.3389 - val_acc: 0.9084\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.3192 - acc: 0.9158 - val_loss: 0.3222 - val_acc: 0.9119\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.2904 - acc: 0.9248 - val_loss: 0.3012 - val_acc: 0.9155\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.3201 - acc: 0.9038 - val_loss: 0.3457 - val_acc: 0.8859\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.2729 - acc: 0.9245 - val_loss: 0.2625 - val_acc: 0.9282\n",
      "\u001b[92m344+298 = 642  ☑ 642 \u001b[0m\n",
      "\u001b[92m270+300 = 570  ☑ 570 \u001b[0m\n",
      "\u001b[92m390+954 = 1344 ☑ 1344\u001b[0m\n",
      "\u001b[91m23+76   = 99   ☒ 98  \u001b[0m\n",
      "\u001b[92m407+489 = 896  ☑ 896 \u001b[0m\n",
      "\u001b[92m453+368 = 821  ☑ 821 \u001b[0m\n",
      "\u001b[92m848+759 = 1607 ☑ 1607\u001b[0m\n",
      "\u001b[92m545+711 = 1256 ☑ 1256\u001b[0m\n",
      "\u001b[92m160+724 = 884  ☑ 884 \u001b[0m\n",
      "\u001b[92m252+942 = 1194 ☑ 1194\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 61us/step - loss: 0.2340 - acc: 0.9411 - val_loss: 0.2535 - val_acc: 0.9283\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.2212 - acc: 0.9441 - val_loss: 0.2335 - val_acc: 0.9366\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.2077 - acc: 0.9477 - val_loss: 0.2244 - val_acc: 0.9381\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1974 - acc: 0.9492 - val_loss: 0.2102 - val_acc: 0.9417\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1859 - acc: 0.9522 - val_loss: 0.2119 - val_acc: 0.9370\n",
      "\u001b[92m762+775 = 1537 ☑ 1537\u001b[0m\n",
      "\u001b[92m966+624 = 1590 ☑ 1590\u001b[0m\n",
      "\u001b[92m975+455 = 1430 ☑ 1430\u001b[0m\n",
      "\u001b[92m224+698 = 922  ☑ 922 \u001b[0m\n",
      "\u001b[91m53+28   = 81   ☒ 12  \u001b[0m\n",
      "\u001b[91m665+41  = 706  ☒ 696 \u001b[0m\n",
      "\u001b[92m550+854 = 1404 ☑ 1404\u001b[0m\n",
      "\u001b[92m956+436 = 1392 ☑ 1392\u001b[0m\n",
      "\u001b[91m841+4   = 845  ☒ 857 \u001b[0m\n",
      "\u001b[92m896+179 = 1075 ☑ 1075\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1770 - acc: 0.9546 - val_loss: 0.1991 - val_acc: 0.9429\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 59us/step - loss: 0.1685 - acc: 0.9569 - val_loss: 0.1882 - val_acc: 0.9454\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1701 - acc: 0.9536 - val_loss: 0.1873 - val_acc: 0.9446\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 0.1599 - acc: 0.9576 - val_loss: 0.1820 - val_acc: 0.9448\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 0.1518 - acc: 0.9597 - val_loss: 0.1677 - val_acc: 0.9513\n",
      "\u001b[91m883+80  = 963  ☒ 903 \u001b[0m\n",
      "\u001b[92m501+322 = 823  ☑ 823 \u001b[0m\n",
      "\u001b[92m859+421 = 1280 ☑ 1280\u001b[0m\n",
      "\u001b[92m634+433 = 1067 ☑ 1067\u001b[0m\n",
      "\u001b[91m194+208 = 402  ☒ 403 \u001b[0m\n",
      "\u001b[92m773+332 = 1105 ☑ 1105\u001b[0m\n",
      "\u001b[92m327+688 = 1015 ☑ 1015\u001b[0m\n",
      "\u001b[91m28+312  = 340  ☒ 330 \u001b[0m\n",
      "\u001b[92m12+360  = 372  ☑ 372 \u001b[0m\n",
      "\u001b[92m515+445 = 960  ☑ 960 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 0.1397 - acc: 0.9640 - val_loss: 0.1751 - val_acc: 0.9466\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1482 - acc: 0.9588 - val_loss: 0.1678 - val_acc: 0.9485\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1285 - acc: 0.9677 - val_loss: 0.1477 - val_acc: 0.9575\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1180 - acc: 0.9712 - val_loss: 0.1442 - val_acc: 0.9582\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1117 - acc: 0.9732 - val_loss: 0.1407 - val_acc: 0.9594\n",
      "\u001b[92m801+575 = 1376 ☑ 1376\u001b[0m\n",
      "\u001b[92m422+263 = 685  ☑ 685 \u001b[0m\n",
      "\u001b[91m69+980  = 1049 ☒ 1058\u001b[0m\n",
      "\u001b[92m316+701 = 1017 ☑ 1017\u001b[0m\n",
      "\u001b[92m842+237 = 1079 ☑ 1079\u001b[0m\n",
      "\u001b[92m743+603 = 1346 ☑ 1346\u001b[0m\n",
      "\u001b[92m686+376 = 1062 ☑ 1062\u001b[0m\n",
      "\u001b[92m399+360 = 759  ☑ 759 \u001b[0m\n",
      "\u001b[92m142+417 = 559  ☑ 559 \u001b[0m\n",
      "\u001b[92m707+806 = 1513 ☑ 1513\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.4214 - acc: 0.8730 - val_loss: 0.3508 - val_acc: 0.8743\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1733 - acc: 0.9464 - val_loss: 0.1493 - val_acc: 0.9569\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1097 - acc: 0.9746 - val_loss: 0.1318 - val_acc: 0.9614\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.1012 - acc: 0.9770 - val_loss: 0.1252 - val_acc: 0.9648\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 0.0950 - acc: 0.9792 - val_loss: 0.1207 - val_acc: 0.9658\n",
      "\u001b[92m505+951 = 1456 ☑ 1456\u001b[0m\n",
      "\u001b[92m590+156 = 746  ☑ 746 \u001b[0m\n",
      "\u001b[92m770+777 = 1547 ☑ 1547\u001b[0m\n",
      "\u001b[92m821+689 = 1510 ☑ 1510\u001b[0m\n",
      "\u001b[92m810+537 = 1347 ☑ 1347\u001b[0m\n",
      "\u001b[91m796+256 = 1052 ☒ 1042\u001b[0m\n",
      "\u001b[92m903+986 = 1889 ☑ 1889\u001b[0m\n",
      "\u001b[92m87+975  = 1062 ☑ 1062\u001b[0m\n",
      "\u001b[92m358+382 = 740  ☑ 740 \u001b[0m\n",
      "\u001b[92m785+226 = 1011 ☑ 1011\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0910 - acc: 0.9797 - val_loss: 0.1182 - val_acc: 0.9659\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0876 - acc: 0.9807 - val_loss: 0.1156 - val_acc: 0.9668\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0855 - acc: 0.9814 - val_loss: 0.1128 - val_acc: 0.9667\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0816 - acc: 0.9826 - val_loss: 0.1128 - val_acc: 0.9661\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0793 - acc: 0.9829 - val_loss: 0.1080 - val_acc: 0.9684\n",
      "\u001b[92m246+186 = 432  ☑ 432 \u001b[0m\n",
      "\u001b[92m578+216 = 794  ☑ 794 \u001b[0m\n",
      "\u001b[92m530+907 = 1437 ☑ 1437\u001b[0m\n",
      "\u001b[92m586+742 = 1328 ☑ 1328\u001b[0m\n",
      "\u001b[92m363+208 = 571  ☑ 571 \u001b[0m\n",
      "\u001b[92m533+672 = 1205 ☑ 1205\u001b[0m\n",
      "\u001b[92m892+526 = 1418 ☑ 1418\u001b[0m\n",
      "\u001b[92m762+898 = 1660 ☑ 1660\u001b[0m\n",
      "\u001b[92m834+39  = 873  ☑ 873 \u001b[0m\n",
      "\u001b[92m841+207 = 1048 ☑ 1048\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0767 - acc: 0.9831 - val_loss: 0.1077 - val_acc: 0.9675\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0744 - acc: 0.9837 - val_loss: 0.1067 - val_acc: 0.9680\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0728 - acc: 0.9839 - val_loss: 0.1052 - val_acc: 0.9677\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0694 - acc: 0.9852 - val_loss: 0.1017 - val_acc: 0.9697\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 0.0678 - acc: 0.9854 - val_loss: 0.0999 - val_acc: 0.9701\n",
      "\u001b[92m483+747 = 1230 ☑ 1230\u001b[0m\n",
      "\u001b[92m658+481 = 1139 ☑ 1139\u001b[0m\n",
      "\u001b[92m833+980 = 1813 ☑ 1813\u001b[0m\n",
      "\u001b[92m138+435 = 573  ☑ 573 \u001b[0m\n",
      "\u001b[92m526+558 = 1084 ☑ 1084\u001b[0m\n",
      "\u001b[92m368+679 = 1047 ☑ 1047\u001b[0m\n",
      "\u001b[91m312+27  = 339  ☒ 349 \u001b[0m\n",
      "\u001b[91m412+127 = 539  ☒ 549 \u001b[0m\n",
      "\u001b[92m585+481 = 1066 ☑ 1066\u001b[0m\n",
      "\u001b[92m919+784 = 1703 ☑ 1703\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 8s 207us/step - loss: 2.1531 - acc: 0.2900 - val_loss: 1.9531 - val_acc: 0.3146\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.9333 - acc: 0.3123 - val_loss: 1.9029 - val_acc: 0.3150\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.8963 - acc: 0.3157 - val_loss: 1.8705 - val_acc: 0.3177\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.8450 - acc: 0.3259 - val_loss: 1.7809 - val_acc: 0.3335\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.6983 - acc: 0.3697 - val_loss: 1.6358 - val_acc: 0.4083\n",
      "\u001b[91m46+973  = 1019 ☒ 100 \u001b[0m\n",
      "\u001b[91m149+134 = 283  ☒ 447 \u001b[0m\n",
      "\u001b[91m441+670 = 1111 ☒ 1000\u001b[0m\n",
      "\u001b[91m797+31  = 828  ☒ 807 \u001b[0m\n",
      "\u001b[91m604+846 = 1450 ☒ 1400\u001b[0m\n",
      "\u001b[91m501+332 = 833  ☒ 809 \u001b[0m\n",
      "\u001b[91m555+688 = 1243 ☒ 1200\u001b[0m\n",
      "\u001b[91m260+329 = 589  ☒ 677 \u001b[0m\n",
      "\u001b[91m815+443 = 1258 ☒ 1200\u001b[0m\n",
      "\u001b[91m941+152 = 1093 ☒ 1100\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.5956 - acc: 0.4176 - val_loss: 1.5681 - val_acc: 0.4197\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.5182 - acc: 0.4478 - val_loss: 1.4765 - val_acc: 0.4621\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.5131 - acc: 0.4376 - val_loss: 1.4600 - val_acc: 0.4601\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.4316 - acc: 0.4775 - val_loss: 1.4082 - val_acc: 0.4901\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.4000 - acc: 0.4852 - val_loss: 1.4207 - val_acc: 0.4645\n",
      "\u001b[91m996+138 = 1134 ☒ 1216\u001b[0m\n",
      "\u001b[91m847+596 = 1443 ☒ 1491\u001b[0m\n",
      "\u001b[91m297+366 = 663  ☒ 626 \u001b[0m\n",
      "\u001b[91m566+801 = 1367 ☒ 1444\u001b[0m\n",
      "\u001b[91m664+518 = 1182 ☒ 1286\u001b[0m\n",
      "\u001b[91m464+963 = 1427 ☒ 1404\u001b[0m\n",
      "\u001b[91m413+454 = 867  ☒ 868 \u001b[0m\n",
      "\u001b[91m789+833 = 1622 ☒ 1621\u001b[0m\n",
      "\u001b[91m154+35  = 189  ☒ 258 \u001b[0m\n",
      "\u001b[91m6+912   = 918  ☒ 408 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.3808 - acc: 0.4886 - val_loss: 1.3676 - val_acc: 0.4940\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.3529 - acc: 0.5005 - val_loss: 1.3483 - val_acc: 0.4931\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.3397 - acc: 0.5020 - val_loss: 1.3299 - val_acc: 0.5029\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.3179 - acc: 0.5106 - val_loss: 1.3187 - val_acc: 0.5050\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.3097 - acc: 0.5100 - val_loss: 1.2984 - val_acc: 0.5183\n",
      "\u001b[91m787+907 = 1694 ☒ 1603\u001b[0m\n",
      "\u001b[91m554+295 = 849  ☒ 848 \u001b[0m\n",
      "\u001b[91m381+950 = 1331 ☒ 1322\u001b[0m\n",
      "\u001b[91m924+978 = 1902 ☒ 1811\u001b[0m\n",
      "\u001b[91m822+379 = 1201 ☒ 1212\u001b[0m\n",
      "\u001b[92m748+864 = 1612 ☑ 1612\u001b[0m\n",
      "\u001b[91m485+358 = 843  ☒ 848 \u001b[0m\n",
      "\u001b[91m275+597 = 872  ☒ 848 \u001b[0m\n",
      "\u001b[91m199+244 = 443  ☒ 411 \u001b[0m\n",
      "\u001b[91m590+843 = 1433 ☒ 1412\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2896 - acc: 0.5205 - val_loss: 1.2777 - val_acc: 0.5199\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.2782 - acc: 0.5242 - val_loss: 1.2649 - val_acc: 0.5296\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2698 - acc: 0.5242 - val_loss: 1.2513 - val_acc: 0.5329\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.2545 - acc: 0.5311 - val_loss: 1.2461 - val_acc: 0.5337\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.2491 - acc: 0.5315 - val_loss: 1.2437 - val_acc: 0.5343\n",
      "\u001b[91m39+18   = 57   ☒ 12  \u001b[0m\n",
      "\u001b[91m335+65  = 400  ☒ 589 \u001b[0m\n",
      "\u001b[91m182+412 = 594  ☒ 582 \u001b[0m\n",
      "\u001b[91m721+943 = 1664 ☒ 1603\u001b[0m\n",
      "\u001b[91m505+472 = 977  ☒ 900 \u001b[0m\n",
      "\u001b[91m560+392 = 952  ☒ 959 \u001b[0m\n",
      "\u001b[91m373+389 = 762  ☒ 700 \u001b[0m\n",
      "\u001b[91m556+697 = 1253 ☒ 1298\u001b[0m\n",
      "\u001b[91m560+990 = 1550 ☒ 1500\u001b[0m\n",
      "\u001b[91m247+213 = 460  ☒ 480 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2274 - acc: 0.5411 - val_loss: 1.2169 - val_acc: 0.5425\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2191 - acc: 0.5416 - val_loss: 1.2028 - val_acc: 0.5542\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.2069 - acc: 0.5476 - val_loss: 1.1962 - val_acc: 0.5466\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.1880 - acc: 0.5534 - val_loss: 1.1806 - val_acc: 0.5517\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.1662 - acc: 0.5628 - val_loss: 1.1531 - val_acc: 0.5633\n",
      "\u001b[91m988+975 = 1963 ☒ 1931\u001b[0m\n",
      "\u001b[91m458+154 = 612  ☒ 611 \u001b[0m\n",
      "\u001b[91m165+898 = 1063 ☒ 1071\u001b[0m\n",
      "\u001b[91m977+499 = 1476 ☒ 1457\u001b[0m\n",
      "\u001b[91m622+395 = 1017 ☒ 1028\u001b[0m\n",
      "\u001b[91m931+620 = 1551 ☒ 1533\u001b[0m\n",
      "\u001b[91m104+762 = 866  ☒ 816 \u001b[0m\n",
      "\u001b[91m501+332 = 833  ☒ 866 \u001b[0m\n",
      "\u001b[91m594+285 = 879  ☒ 808 \u001b[0m\n",
      "\u001b[91m539+571 = 1110 ☒ 1100\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.1515 - acc: 0.5631 - val_loss: 1.1340 - val_acc: 0.5676\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.1147 - acc: 0.5802 - val_loss: 1.0860 - val_acc: 0.5984\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.0791 - acc: 0.5962 - val_loss: 1.0614 - val_acc: 0.6000\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.0288 - acc: 0.6208 - val_loss: 1.0261 - val_acc: 0.6096\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.9924 - acc: 0.6308 - val_loss: 0.9645 - val_acc: 0.6349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m738+506 = 1244 ☒ 1245\u001b[0m\n",
      "\u001b[91m782+809 = 1591 ☒ 1500\u001b[0m\n",
      "\u001b[92m385+579 = 964  ☑ 964 \u001b[0m\n",
      "\u001b[91m959+174 = 1133 ☒ 1123\u001b[0m\n",
      "\u001b[92m731+767 = 1498 ☑ 1498\u001b[0m\n",
      "\u001b[91m581+288 = 869  ☒ 848 \u001b[0m\n",
      "\u001b[91m744+134 = 878  ☒ 886 \u001b[0m\n",
      "\u001b[91m824+981 = 1805 ☒ 1802\u001b[0m\n",
      "\u001b[91m410+662 = 1072 ☒ 1066\u001b[0m\n",
      "\u001b[91m234+93  = 327  ☒ 410 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.9370 - acc: 0.6482 - val_loss: 0.8845 - val_acc: 0.6671\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.8363 - acc: 0.6892 - val_loss: 0.7879 - val_acc: 0.7152\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.7486 - acc: 0.7333 - val_loss: 0.7012 - val_acc: 0.7620\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.6779 - acc: 0.7648 - val_loss: 0.6408 - val_acc: 0.7854\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.6241 - acc: 0.7867 - val_loss: 0.5983 - val_acc: 0.7968\n",
      "\u001b[92m381+366 = 747  ☑ 747 \u001b[0m\n",
      "\u001b[92m952+361 = 1313 ☑ 1313\u001b[0m\n",
      "\u001b[92m421+689 = 1110 ☑ 1110\u001b[0m\n",
      "\u001b[91m973+489 = 1462 ☒ 1452\u001b[0m\n",
      "\u001b[91m953+618 = 1571 ☒ 1561\u001b[0m\n",
      "\u001b[92m684+965 = 1649 ☑ 1649\u001b[0m\n",
      "\u001b[91m514+305 = 819  ☒ 839 \u001b[0m\n",
      "\u001b[92m840+312 = 1152 ☑ 1152\u001b[0m\n",
      "\u001b[92m740+739 = 1479 ☑ 1479\u001b[0m\n",
      "\u001b[91m942+84  = 1026 ☒ 902 \u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.5597 - acc: 0.8186 - val_loss: 0.5351 - val_acc: 0.8306\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.5106 - acc: 0.8413 - val_loss: 0.5061 - val_acc: 0.8322\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.4711 - acc: 0.8556 - val_loss: 0.4608 - val_acc: 0.8560\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.4376 - acc: 0.8686 - val_loss: 0.4302 - val_acc: 0.8687\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.4146 - acc: 0.8729 - val_loss: 0.4045 - val_acc: 0.8722\n",
      "\u001b[92m868+616 = 1484 ☑ 1484\u001b[0m\n",
      "\u001b[92m352+753 = 1105 ☑ 1105\u001b[0m\n",
      "\u001b[91m46+884  = 930  ☒ 922 \u001b[0m\n",
      "\u001b[91m515+313 = 828  ☒ 838 \u001b[0m\n",
      "\u001b[91m278+173 = 451  ☒ 441 \u001b[0m\n",
      "\u001b[92m160+377 = 537  ☑ 537 \u001b[0m\n",
      "\u001b[91m718+208 = 926  ☒ 936 \u001b[0m\n",
      "\u001b[91m120+172 = 292  ☒ 302 \u001b[0m\n",
      "\u001b[92m118+433 = 551  ☑ 551 \u001b[0m\n",
      "\u001b[92m894+218 = 1112 ☑ 1112\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.3843 - acc: 0.8838 - val_loss: 0.3907 - val_acc: 0.8764\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.3627 - acc: 0.8903 - val_loss: 0.3602 - val_acc: 0.8894\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.3415 - acc: 0.8955 - val_loss: 0.3441 - val_acc: 0.8917\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.3281 - acc: 0.8980 - val_loss: 0.3302 - val_acc: 0.8927\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.3110 - acc: 0.9026 - val_loss: 0.3104 - val_acc: 0.9004\n",
      "\u001b[92m911+408 = 1319 ☑ 1319\u001b[0m\n",
      "\u001b[91m344+854 = 1198 ☒ 1298\u001b[0m\n",
      "\u001b[92m211+173 = 384  ☑ 384 \u001b[0m\n",
      "\u001b[92m733+752 = 1485 ☑ 1485\u001b[0m\n",
      "\u001b[92m438+882 = 1320 ☑ 1320\u001b[0m\n",
      "\u001b[91m151+58  = 209  ☒ 290 \u001b[0m\n",
      "\u001b[92m840+904 = 1744 ☑ 1744\u001b[0m\n",
      "\u001b[92m597+723 = 1320 ☑ 1320\u001b[0m\n",
      "\u001b[91m404+21  = 425  ☒ 456 \u001b[0m\n",
      "\u001b[91m708+500 = 1208 ☒ 1218\u001b[0m\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 0.2937 - acc: 0.9090 - val_loss: 0.2944 - val_acc: 0.9061\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.2775 - acc: 0.9140 - val_loss: 0.2811 - val_acc: 0.9107\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.2644 - acc: 0.9172 - val_loss: 0.2724 - val_acc: 0.9101\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 0.2494 - acc: 0.9231 - val_loss: 0.2505 - val_acc: 0.9219\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 0.2359 - acc: 0.9267 - val_loss: 0.2421 - val_acc: 0.9226\n",
      "\u001b[92m479+233 = 712  ☑ 712 \u001b[0m\n",
      "\u001b[91m4+920   = 924  ☒ 746 \u001b[0m\n",
      "\u001b[92m574+329 = 903  ☑ 903 \u001b[0m\n",
      "\u001b[91m116+85  = 201  ☒ 211 \u001b[0m\n",
      "\u001b[92m781+494 = 1275 ☑ 1275\u001b[0m\n",
      "\u001b[92m649+428 = 1077 ☑ 1077\u001b[0m\n",
      "\u001b[92m235+851 = 1086 ☑ 1086\u001b[0m\n",
      "\u001b[91m636+243 = 879  ☒ 889 \u001b[0m\n",
      "\u001b[92m927+196 = 1123 ☑ 1123\u001b[0m\n",
      "\u001b[92m148+622 = 770  ☑ 770 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(HIDDEN_SIZE, input_shape=(MAXLEN, ALPHABET_LENGTH))) # Encoder\n",
    "rnn_model.add(RepeatVector(DIGITS + 1))\n",
    "rnn_model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=True)) # Decoder\n",
    "rnn_model.add(TimeDistributed(Dense(ALPHABET_LENGTH, activation='softmax')))\n",
    "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "rnn_loss, rnn_acc, rnn_val_loss, rnn_val_acc = train(rnn_model, X_train, y_train, X_val, y_val, encoder, EPOCHS)\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(HIDDEN_SIZE, input_shape=(MAXLEN, ALPHABET_LENGTH))) # Encoder\n",
    "gru_model.add(RepeatVector(DIGITS + 1))\n",
    "gru_model.add(GRU(HIDDEN_SIZE, return_sequences=True)) # Decoder\n",
    "gru_model.add(TimeDistributed(Dense(ALPHABET_LENGTH, activation='softmax')))\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "gru_loss, gru_acc, gru_val_loss, gru_val_acc = train(gru_model, X_train, y_train, X_val, y_val, encoder, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T19:04:16.225867Z",
     "start_time": "2019-05-28T19:04:15.989153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effa407cf28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(new_loss, label='RNN loss')\n",
    "plt.plot(new_val_loss, label='RNN val loss')\n",
    "plt.plot(loss, label='LSTM loss')\n",
    "plt.plot(val_loss, label='LSTM val loss')\n",
    "plt.plot(pre_loss, label='GRU loss')\n",
    "plt.plot(pre_val_loss, label='GRU val loss pretrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
